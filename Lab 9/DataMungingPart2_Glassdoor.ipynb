{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "cell_id": "5ba6e568-cfda-4b16-8d01-3556c9ede91b",
    "id": "ZFDtcJI0wYUv",
    "output_cleared": false
   },
   "source": [
    "# Data Munging Part II - Filtering and Joining Datasets\n",
    "This lab was adapted from # Glassdoor Jobs Data-Analysis \n",
    "https://github.com/Atharva-Phatak/Glassdoor-Jobs_Data-Analysis\n",
    "\n",
    "In Data Munging Part I we learned how to explore our data and clean it up so that missing values are removed.\n",
    "\n",
    "In this Data Munging Part II lab, we are going to learn how to:\n",
    "1. Filter our Data\n",
    "2. Sort Data \n",
    "3. Merge/Concatenate Data Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZxxyHYZiwYUw"
   },
   "source": [
    "Recall that the point of data munging is to `wrangle` multiple data sources so that you can begin to perform data analysis on the data that you were given or scraped from the web. \n",
    "\n",
    "In most cases you are given a dataset and you must supplement your dataset with sources from web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUYKcATzwYUx"
   },
   "source": [
    "In this lab we will perform analysis of Glassdoor data\n",
    "\n",
    "## About Glassdoor\n",
    "\n",
    "![glass](https://upload.wikimedia.org/wikipedia/commons/e/e1/Glassdoor_logo.svg)\n",
    "\n",
    "\"Glassdoor is one of the world’s largest job and recruiting sites.\n",
    "\n",
    "Built on the foundation of increasing workplace transparency, Glassdoor offers millions of the latest job listings, combined with a growing database of company reviews, CEO approval ratings, salary reports, interview reviews and questions, benefits reviews, office photos and more. Unlike other job sites, all of this information is shared by those who know a company best — the employees. In turn, job seekers on Glassdoor are well-researched and more informed about the jobs and companies they apply to and consider joining. This is why thousands of employers across all industries and sizes turn to Glassdoor to help them recruit and hire quality candidates at scale who stay longer. Glassdoor is available anywhere via its mobile apps.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vINPQODEwYU2"
   },
   "source": [
    "## Q1. Write the code to import the pandas, numpy, and matplotlib.pyplot libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 489,
     "status": "ok",
     "timestamp": 1605387473441,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "GpGtvZKVwYU2"
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98yCDjKzwYU5"
   },
   "source": [
    "# More Data Cleaning\n",
    "\n",
    "In the next block we are improting the libraries `plotly.express`, `gc`, `re`, and `yellowbrick`. \n",
    "\n",
    "## The gc python library\n",
    "This library is a Garbage Collector¶. This module provides an interface to the optional garbage collector.\n",
    "- It is useful for when you are working with large datasets and you pull out useful informatin from these large datasets and store them in a separate dataframe.\n",
    "- Also useful if you have limited space. Some cloud servers only allow you to use a certain amount of space for free services.  (i.e. Collab, jupyter notebooks, etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaGhViMAwYU5"
   },
   "source": [
    "# The re library\n",
    "This is the regular expression library. You should have already been introduced to this in a previous lab. \n",
    "Go here: https://docs.python.org/3/library/re.html for more information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1SoXReWwYU5"
   },
   "source": [
    "# Yellowbrick library\n",
    "visual analysis and diagnostic tools\n",
    "you may need to install it to get it to work\n",
    "\n",
    "`pip install yellowbrick`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13040,
     "status": "ok",
     "timestamp": 1605387486001,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "sJXSiku-wYU6",
    "outputId": "58021228-94b8-456d-bfb1-98021d142020"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.8/site-packages (4.11.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /opt/conda/lib/python3.8/site-packages (from plotly) (1.3.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from plotly) (1.15.0)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.8/site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.19.2)\n",
      "Requirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.1.3)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /opt/conda/lib/python3.8/site-packages (from seaborn) (3.3.2)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2020.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2020.6.20)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (8.0.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas>=0.23->seaborn) (1.15.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.8/site-packages (3.4.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from nltk) (1.15.0)\n",
      "Collecting gensim\n",
      "  Downloading gensim-3.8.3-cp38-cp38-manylinux1_x86_64.whl (24.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.2 MB 4.1 MB/s eta 0:00:01 MB 4.1 MB/s eta 0:00:06\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.8/site-packages (from gensim) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.8/site-packages (from gensim) (1.19.2)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-4.0.1.tar.gz (117 kB)\n",
      "\u001b[K     |████████████████████████████████| 117 kB 46.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from gensim) (1.15.0)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-4.0.1-py3-none-any.whl size=108249 sha256=f0834ef94b1e070d439131330f57b1cea44d53b1416ddf7695fdc0c5e5eae598\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/8c/f9/f4/4ddd9ddee3488f48be20e9bf3108961f03ae23da29b7ed26d1\n",
      "Successfully built smart-open\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-3.8.3 smart-open-4.0.1\n",
      "Collecting yellowbrick\n",
      "  Downloading yellowbrick-1.2-py3-none-any.whl (269 kB)\n",
      "\u001b[K     |████████████████████████████████| 269 kB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from yellowbrick) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.13.0 in /opt/conda/lib/python3.8/site-packages (from yellowbrick) (1.19.2)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from yellowbrick) (3.3.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in /opt/conda/lib/python3.8/site-packages (from yellowbrick) (0.23.2)\n",
      "Requirement already satisfied: cycler>=0.10.0 in /opt/conda/lib/python3.8/site-packages (from yellowbrick) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.2.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (8.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.20->yellowbrick) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.20->yellowbrick) (2.1.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from cycler>=0.10.0->yellowbrick) (1.15.0)\n",
      "Installing collected packages: yellowbrick\n",
      "Successfully installed yellowbrick-1.2\n"
     ]
    }
   ],
   "source": [
    "# Note if anything isn't working in this tutorial you may need to install it. See below\n",
    "!pip3 install plotly\n",
    "!pip install seaborn\n",
    "!pip install nltk\n",
    "!pip install gensim\n",
    "!pip install yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "cell_id": "517b3ecd-c2a1-47ad-b6a8-aa965e168770",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18126,
     "status": "ok",
     "timestamp": 1605387491098,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "5tIp8L3ZwYU9",
    "outputId": "09f62ea8-10e6-4ebb-e4ae-96cc64a85c3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (1.1.3)\n",
      "Collecting plotnine\n",
      "  Downloading plotnine-0.7.1-py3-none-any.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 4.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.8/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /opt/conda/lib/python3.8/site-packages (from pandas) (1.19.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: matplotlib>=3.1.1 in /opt/conda/lib/python3.8/site-packages (from plotnine) (3.3.2)\n",
      "Requirement already satisfied: statsmodels>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from plotnine) (0.12.0)\n",
      "Collecting mizani>=0.7.1\n",
      "  Downloading mizani-0.7.2-py3-none-any.whl (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 629 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting descartes>=1.1.0\n",
      "  Downloading descartes-1.1.0-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /opt/conda/lib/python3.8/site-packages (from plotnine) (0.5.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.8/site-packages (from plotnine) (1.5.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.1.1->plotnine) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.1.1->plotnine) (1.2.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.1.1->plotnine) (2020.6.20)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.1.1->plotnine) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.1.1->plotnine) (8.0.0)\n",
      "Collecting palettable\n",
      "  Downloading palettable-3.3.0-py2.py3-none-any.whl (111 kB)\n",
      "\u001b[K     |████████████████████████████████| 111 kB 46.8 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: palettable, mizani, descartes, plotnine\n",
      "Successfully installed descartes-1.1.0 mizani-0.7.2 palettable-3.3.0 plotnine-0.7.1\n",
      "Requirement already satisfied: datascience in /opt/conda/lib/python3.8/site-packages (0.17.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datascience) (1.1.3)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from datascience) (3.3.2)\n",
      "Requirement already satisfied: ipython in /opt/conda/lib/python3.8/site-packages (from datascience) (7.18.1)\n",
      "Requirement already satisfied: sphinx in /opt/conda/lib/python3.8/site-packages (from datascience) (3.2.1)\n",
      "Requirement already satisfied: nbsphinx in /opt/conda/lib/python3.8/site-packages (from datascience) (0.7.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from datascience) (1.19.2)\n",
      "Requirement already satisfied: coverage in /opt/conda/lib/python3.8/site-packages (from datascience) (5.3)\n",
      "Requirement already satisfied: folium>=0.9.1 in /opt/conda/lib/python3.8/site-packages (from datascience) (0.11.0)\n",
      "Requirement already satisfied: coveralls in /opt/conda/lib/python3.8/site-packages (from datascience) (2.1.2)\n",
      "Requirement already satisfied: pytest in /opt/conda/lib/python3.8/site-packages (from datascience) (6.1.1)\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.8/site-packages (from datascience) (4.11.0)\n",
      "Requirement already satisfied: bokeh in /opt/conda/lib/python3.8/site-packages (from datascience) (2.2.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from datascience) (1.5.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from datascience) (49.6.0.post20201009)\n",
      "Requirement already satisfied: branca in /opt/conda/lib/python3.8/site-packages (from datascience) (0.4.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.8/site-packages (from pandas->datascience) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datascience) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.0.0->datascience) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.0.0->datascience) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.0.0->datascience) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.0.0->datascience) (8.0.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.0.0->datascience) (2020.6.20)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.8/site-packages (from ipython->datascience) (0.17.2)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython->datascience) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython->datascience) (4.4.2)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython->datascience) (2.7.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipython->datascience) (4.3.3)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython->datascience) (3.0.8)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython->datascience) (0.7.5)\n",
      "Requirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in /opt/conda/lib/python3.8/site-packages (from ipython->datascience) (4.8.0)\n",
      "Requirement already satisfied: docutils>=0.12 in /opt/conda/lib/python3.8/site-packages (from sphinx->datascience) (0.16)\n",
      "Requirement already satisfied: Jinja2>=2.3 in /opt/conda/lib/python3.8/site-packages (from sphinx->datascience) (2.11.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from sphinx->datascience) (20.4)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp in /opt/conda/lib/python3.8/site-packages (from sphinx->datascience) (1.0.3)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in /opt/conda/lib/python3.8/site-packages (from sphinx->datascience) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml in /opt/conda/lib/python3.8/site-packages (from sphinx->datascience) (1.1.4)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in /opt/conda/lib/python3.8/site-packages (from sphinx->datascience) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in /opt/conda/lib/python3.8/site-packages (from sphinx->datascience) (1.0.2)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /opt/conda/lib/python3.8/site-packages (from sphinx->datascience) (0.7.12)\n",
      "Requirement already satisfied: requests>=2.5.0 in /opt/conda/lib/python3.8/site-packages (from sphinx->datascience) (2.24.0)\n",
      "Requirement already satisfied: babel>=1.3 in /opt/conda/lib/python3.8/site-packages (from sphinx->datascience) (2.8.0)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in /opt/conda/lib/python3.8/site-packages (from sphinx->datascience) (1.0.3)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /opt/conda/lib/python3.8/site-packages (from sphinx->datascience) (2.0.0)\n",
      "Requirement already satisfied: imagesize in /opt/conda/lib/python3.8/site-packages (from sphinx->datascience) (1.2.0)\n",
      "Requirement already satisfied: nbconvert!=5.4 in /opt/conda/lib/python3.8/site-packages (from nbsphinx->datascience) (5.6.1)\n",
      "Requirement already satisfied: nbformat in /opt/conda/lib/python3.8/site-packages (from nbsphinx->datascience) (4.4.0)\n",
      "Requirement already satisfied: docopt>=0.6.1 in /opt/conda/lib/python3.8/site-packages (from coveralls->datascience) (0.6.2)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /opt/conda/lib/python3.8/site-packages (from pytest->datascience) (0.13.1)\n",
      "Requirement already satisfied: toml in /opt/conda/lib/python3.8/site-packages (from pytest->datascience) (0.10.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from pytest->datascience) (20.2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.8/site-packages (from pytest->datascience) (1.1.1)\n",
      "Requirement already satisfied: py>=1.8.2 in /opt/conda/lib/python3.8/site-packages (from pytest->datascience) (1.9.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /opt/conda/lib/python3.8/site-packages (from plotly->datascience) (1.3.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from plotly->datascience) (1.15.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /opt/conda/lib/python3.8/site-packages (from bokeh->datascience) (5.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.8/site-packages (from bokeh->datascience) (3.7.4.3)\n",
      "Requirement already satisfied: tornado>=5.1 in /opt/conda/lib/python3.8/site-packages (from bokeh->datascience) (6.0.4)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.10->ipython->datascience) (0.7.1)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from traitlets>=4.2->ipython->datascience) (0.2.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->datascience) (0.2.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3; sys_platform != \"win32\"->ipython->datascience) (0.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.8/site-packages (from Jinja2>=2.3->sphinx->datascience) (1.1.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.5.0->sphinx->datascience) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests>=2.5.0->sphinx->datascience) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.5.0->sphinx->datascience) (1.25.10)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->datascience) (0.3)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->datascience) (0.8.4)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->datascience) (0.6.0)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->datascience) (0.4.4)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->datascience) (4.6.3)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->datascience) (3.2.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->datascience) (1.4.2)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbformat->nbsphinx->datascience) (3.2.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert!=5.4->nbsphinx->datascience) (0.5.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->nbsphinx->datascience) (0.17.3)\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import nltk \n",
    "import plotly.express as px\n",
    "import gc\n",
    "import string\n",
    "import re\n",
    "import yellowbrick\n",
    "\n",
    "!pip install pandas plotnine\n",
    "!pip install datascience\n",
    "\n",
    "from plotnine import *\n",
    "from datascience import *\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "pd.options.display.max_columns = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyQymZB-wYU_"
   },
   "source": [
    "## Q2. Write the code to use pandas to load the csv files Data_Job_NY.csv, Data_Job_SF.csv, Data_Job_TX.csv, and Data_Job_WA.csv into dataframes.\n",
    "Name the dataframes `ny_df`, `sf_df`, `tx_df`, and `wa_df`\n",
    "\n",
    "Remember that your csv files should be located in the data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 19926,
     "status": "ok",
     "timestamp": 1605387492909,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "TRxWJZv_wYVA",
    "outputId": "bdc39e68-8fac-4995-fedb-ebe2355c534c"
   },
   "outputs": [],
   "source": [
    "# Load the datasets NY, SF, TX, WA\n",
    "data_job_NY = pd.read_csv(\"Data_Job_NY.csv\")\n",
    "data_job_SF = pd.read_csv(\"Data_Job_SF.csv\")\n",
    "data_job_TX = pd.read_csv(\"Data_Job_TX.csv\")\n",
    "data_job_WA = pd.read_csv(\"Data_Job_WA.csv\")\n",
    "\n",
    "data_job_WA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S07Hfd9ywYVD"
   },
   "source": [
    "## Q3. Write the code to print out the count, mean, std, min, and max of all of the datasets loaded. \n",
    "Note: You'll have to run the code in a separate cell for each of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "executionInfo": {
     "elapsed": 20725,
     "status": "ok",
     "timestamp": 1605387493719,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "UGeOLnbtwYVD",
    "outputId": "8bc44bac-6be6-4265-e3b2-82a433179eec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min_Salary</th>\n",
       "      <th>Max_Salary</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>900.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33789.711111</td>\n",
       "      <td>49847.461111</td>\n",
       "      <td>3.922727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>40201.559469</td>\n",
       "      <td>59552.391775</td>\n",
       "      <td>0.651320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>64829.000000</td>\n",
       "      <td>87057.000000</td>\n",
       "      <td>4.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>125410.000000</td>\n",
       "      <td>212901.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Min_Salary     Max_Salary      Rating\n",
       "index                                          \n",
       "count  900.000000     900.000000     900.000000\n",
       "mean   33789.711111   49847.461111   3.922727  \n",
       "std    40201.559469   59552.391775   0.651320  \n",
       "min   -1.000000      -1.000000       2.500000  \n",
       "25%   -1.000000      -1.000000       3.500000  \n",
       "50%    20000.000000   35000.000000   4.000000  \n",
       "75%    64829.000000   87057.000000   4.300000  \n",
       "max    125410.000000  212901.000000  5.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_stats(df):\n",
    "  index_for_df = [\"count\", \"mean\", \"std\", \"min\", \"25%\", \"50%\", \"75%\", \"max\"]\n",
    "  min_salary = []\n",
    "  max_salary = []\n",
    "  rating = []\n",
    "\n",
    "  temp_stats = df.count()\n",
    "  min_salary.append(temp_stats[0])\n",
    "  max_salary.append(temp_stats[1])\n",
    "  rating.append(temp_stats[2])\n",
    "\n",
    "  temp_stats = df.mean()\n",
    "  min_salary.append(temp_stats[0])\n",
    "  max_salary.append(temp_stats[1])\n",
    "  rating.append(temp_stats[2])\n",
    "  \n",
    "  temp_stats = df.std()\n",
    "  min_salary.append(temp_stats[0])\n",
    "  max_salary.append(temp_stats[1])\n",
    "  rating.append(temp_stats[2])\n",
    "  \n",
    "  min_salary.append(df[\"Min_Salary\"].min())\n",
    "  max_salary.append(df[\"Max_Salary\"].min())\n",
    "  rating.append(df[\"Rating\"].min())\n",
    "\n",
    "  temp_stats = df.quantile(0.25)\n",
    "  min_salary.append(temp_stats[0])\n",
    "  max_salary.append(temp_stats[1])\n",
    "  rating.append(temp_stats[2])\n",
    "  \n",
    "  temp_stats = df.quantile(0.5)\n",
    "  min_salary.append(temp_stats[0])\n",
    "  max_salary.append(temp_stats[1])\n",
    "  rating.append(temp_stats[2])\n",
    "  \n",
    "  temp_stats = df.quantile(0.75)\n",
    "  min_salary.append(temp_stats[0])\n",
    "  max_salary.append(temp_stats[1])\n",
    "  rating.append(temp_stats[2])\n",
    "  \n",
    "  min_salary.append(df[\"Min_Salary\"].max())\n",
    "  max_salary.append(df[\"Max_Salary\"].max())\n",
    "  rating.append(df[\"Rating\"].max())\n",
    "\n",
    "  # create a new dataframe\n",
    "  stats_df = pd.DataFrame({\"index\": index_for_df, \"Min_Salary\" : min_salary, \"Max_Salary\" : max_salary,  \"Rating\" : rating})\n",
    "  stats_df = stats_df.set_index(\"index\")\n",
    "  return stats_df\n",
    "\n",
    "NY_stats = generate_stats(data_job_NY)\n",
    "NY_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "executionInfo": {
     "elapsed": 20824,
     "status": "ok",
     "timestamp": 1605387493830,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "1b3jfW0ZwYVG",
    "outputId": "49cf7ec9-1ef2-4a7e-e58e-dcfc31ad0242"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min_Salary</th>\n",
       "      <th>Max_Salary</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.00000</td>\n",
       "      <td>889.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75989.293588</td>\n",
       "      <td>105111.84027</td>\n",
       "      <td>3.915223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>56101.457881</td>\n",
       "      <td>75131.99965</td>\n",
       "      <td>0.666049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>3.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>88309.000000</td>\n",
       "      <td>125886.00000</td>\n",
       "      <td>3.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>117464.000000</td>\n",
       "      <td>160387.00000</td>\n",
       "      <td>4.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>205735.000000</td>\n",
       "      <td>315439.00000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Min_Salary    Max_Salary      Rating\n",
       "index                                         \n",
       "count  889.000000     889.00000     889.000000\n",
       "mean   75989.293588   105111.84027  3.915223  \n",
       "std    56101.457881   75131.99965   0.666049  \n",
       "min   -1.000000      -1.00000       1.300000  \n",
       "25%   -1.000000      -1.00000       3.600000  \n",
       "50%    88309.000000   125886.00000  3.900000  \n",
       "75%    117464.000000  160387.00000  4.400000  \n",
       "max    205735.000000  315439.00000  5.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SF_stats = generate_stats(data_job_SF)\n",
    "SF_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "executionInfo": {
     "elapsed": 21247,
     "status": "ok",
     "timestamp": 1605387494264,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "PsHPJkpHwYVI",
    "outputId": "d27b02cb-76ae-499c-d853-f904f3ccceea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min_Salary</th>\n",
       "      <th>Max_Salary</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>643.000000</td>\n",
       "      <td>643.000000</td>\n",
       "      <td>643.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49856.833593</td>\n",
       "      <td>75973.337481</td>\n",
       "      <td>3.742589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>37174.830891</td>\n",
       "      <td>55070.548762</td>\n",
       "      <td>0.593329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>51465.000000</td>\n",
       "      <td>86476.000000</td>\n",
       "      <td>3.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>77272.000000</td>\n",
       "      <td>114060.000000</td>\n",
       "      <td>4.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>195818.000000</td>\n",
       "      <td>383416.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Min_Salary     Max_Salary      Rating\n",
       "index                                          \n",
       "count  643.000000     643.000000     643.000000\n",
       "mean   49856.833593   75973.337481   3.742589  \n",
       "std    37174.830891   55070.548762   0.593329  \n",
       "min   -1.000000      -1.000000       1.000000  \n",
       "25%   -1.000000      -1.000000       3.400000  \n",
       "50%    51465.000000   86476.000000   3.800000  \n",
       "75%    77272.000000   114060.000000  4.100000  \n",
       "max    195818.000000  383416.000000  5.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TX_stats = generate_stats(data_job_TX)\n",
    "TX_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "executionInfo": {
     "elapsed": 21971,
     "status": "ok",
     "timestamp": 1605387494999,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "eUBCUrgZwYVL",
    "outputId": "310bc5ce-7209-4bb9-9a51-2217696f8f94"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min_Salary</th>\n",
       "      <th>Max_Salary</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>892.000000</td>\n",
       "      <td>890.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60523.627803</td>\n",
       "      <td>92022.095291</td>\n",
       "      <td>3.758564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>41024.359069</td>\n",
       "      <td>59570.260961</td>\n",
       "      <td>0.567140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27842.000000</td>\n",
       "      <td>56870.000000</td>\n",
       "      <td>3.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>67662.000000</td>\n",
       "      <td>106081.500000</td>\n",
       "      <td>3.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>90930.250000</td>\n",
       "      <td>128731.250000</td>\n",
       "      <td>4.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>179685.000000</td>\n",
       "      <td>294949.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Min_Salary     Max_Salary      Rating\n",
       "index                                          \n",
       "count  892.000000     892.000000     890.000000\n",
       "mean   60523.627803   92022.095291   3.758564  \n",
       "std    41024.359069   59570.260961   0.567140  \n",
       "min   -1.000000      -1.000000       1.000000  \n",
       "25%    27842.000000   56870.000000   3.400000  \n",
       "50%    67662.000000   106081.500000  3.700000  \n",
       "75%    90930.250000   128731.250000  4.100000  \n",
       "max    179685.000000  294949.000000  5.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WA_stats = generate_stats(data_job_WA)\n",
    "WA_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DmPHqH25wYVN"
   },
   "source": [
    "## Q4. Write the code to print the first 2 rows of the NY dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 21960,
     "status": "ok",
     "timestamp": 1605387495000,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "VM9LFlHBwYVN",
    "outputId": "5a417b1f-fed8-42c8-a0bf-18f3aa87a5a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Min_Salary</th>\n",
       "      <th>Max_Salary</th>\n",
       "      <th>Job_Desc</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date_Posted</th>\n",
       "      <th>Valid_until</th>\n",
       "      <th>Job_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chief Marketing Officer (CMO)</td>\n",
       "      <td>National Debt Relief</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Who We're Looking For:\\n\\nThe Chief Marketing Officer (CMO) is an exempt, executive position, responsible for all marketing operations of the company including lead acquisition, sales enablement, communications, retention, and brand development. This executive leads a team of enthusiastic, analytical, and passionate marketing professionals to develop, execute, and optimize the marketing strategy. We are looking for someone with a history of brand development and proven ability to accelerate company growth leveraging the latest marketing strategies and technologies. This role goes beyond traditional marketing tactics to generate awareness, educate the consumer on the viability of our service, and in turn drive the consumer to take action and engage the brand.\\n\\nPrincipal Duties and Responsibilities:\\n\\nLead the full marketing strategy and have accountability over development, execution, and optimization across all channels including paid and organic search, display, email, social, TV, radio, direct mail, and affiliate marketing.\\nCommunicate with the leadership team and key stakeholders to execute lead generation, sales enablement, and retention-based marketing campaigns that align with and deliver against business goals.\\nDevelop and execute social media, content, and communication strategies to further our public relations and community engagement.\\nIdentify, forge, and grow strategic marketing partnerships.\\nBuild a highly efficient and capable team of marketing professionals.\\nDefine the competitive marketplace and evolve our brand awareness through strategy development and brand building tactics.\\nLead research and development into new marketing tactics and strategies while improving current systems.\\nEstablish key metrics and manage goals while leading the improvement of our pipeline for sales.\\nEstablish framework for all marketing activity, tracking results and reporting progress with management.\\nDevelop segmentation, competitive analysis, market intelligence, salesforce effectiveness, strategic planning and revenue retention and growth.\\n\\nQualifications:\\n\\nA completed BS degree in Business, Marketing, Advertising or other related discipline.\\nMinimum experience required 10+ years of professional experience in a leadership marketing role.\\nExperience building and executing brand awareness and public relations campaigns.\\nExperience in a fast-growing company with a track record of delivering big results.\\nHighly proficient and effective communication skills\\nAbility to utilize data analytics to deliver insight and identify opportunities for growth.\\nA strong record of developing successful, innovative and cost-effective marketing campaigns.\\nPunctual and ready to report to work on a consistent basis.\\nTravel up to 25 percent of the time.\\nExcel in a fast-paced environment.\\n\\nWhat We Offer:\\n\\nA team-first, work hard play hard culture, full of rewards and recognition for our employees. We are dedicated to our employees' success and growth.\\n\\nOur extensive benefits package includes:\\n\\n\\nGenerous Medical, Dental, and Vision Benefits\\n401(k) with Company Match\\nPaid Holidays, Volunteer Time Off, Sick Days, and Vacation\\n10 weeks Paid Parental Leave\\nPre-tax Transit Benefits\\nDiscounted Gym Membership\\nCiti Bike Annual Membership Discounts\\nNo-Cost Life Insurance Benefits\\nVoluntary Benefits Options\\nASPCA Pet Health Insurance Discount\\n\\nAbout National Debt Relief:\\n\\nNational Debt Relief is one of the country's largest and most reputable debt settlement companies. We are made up of energetic, smart, and compassionate individuals who are passionate about helping thousands of Americans with debt relief. Most importantly, we're all about helping our customers through a tough financial time in their lives with education and individual customer service.\\n\\nWe are dedicated to helping individuals and families rid their lives of burdensome debt. We specialize in debt settlement and have negotiated settlements for thousands of creditor and collections accounts. We provide our clients with both our expertise and our proven results. This means helping consumers in their time of hardship to get out of debt with the least possible cost. It can also mean conducting financial consultations, educating the consumer, and recommending the appropriate solution. Our core services offer debt settlement as an alternative to bankruptcy, credit counseling, and debt consolidation. We become our clients' number one advocate to help them reestablish financial stability as quickly as possible.\\n\\nNational Debt Relief is a certified Great Place to Work®!\\n\\nNational Debt Relief is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability status, or any other status protected by law\\n\\n#ZR</td>\n",
       "      <td>Finance</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>2020-06-07</td>\n",
       "      <td>FULL_TIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Registered Nurse</td>\n",
       "      <td>Queens Boulevard Endoscopy Center</td>\n",
       "      <td>NY</td>\n",
       "      <td>Rego Park</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Queens Boulevard Endoscopy Center, an endoscopy ASC located in Rego Park, has an exciting opportunity for Full-Time Registered Nurse! Successful candidates will provide quality nursing care in all areas of the Center including pre-assessment, pre-op and pacu  Qualified candidates must possess the following:\\n\\nCurrent NY state RN license\\nBLS Certification, ACLS preferred\\nMust be a team-player with excellent multi-tasking and interpersonal skills\\nCompassion for patient needs and a high degree of professionalism\\nChinese Speaking and Spanish Preferred\\n\\nQueens Boulevard Endoscopy Center offers a pleasant professional work environment and no evening or holiday work hours. Drug-free work environment and EOE.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020-04-25</td>\n",
       "      <td>2020-06-07</td>\n",
       "      <td>FULL_TIME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Job_title  ...   Job_Type\n",
       "0  Chief Marketing Officer (CMO)  ...  FULL_TIME\n",
       "1  Registered Nurse               ...  FULL_TIME\n",
       "\n",
       "[2 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_job_NY.iloc[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7ZGko9IwYVQ"
   },
   "source": [
    "## Q5. Write the code to print the name of the columns for only one of the dataframes\n",
    "\n",
    "Note: the data was scrapted from glassdoor and will have the same column information for each dataframe loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21950,
     "status": "ok",
     "timestamp": 1605387495001,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "tXmAAYHXwYVQ",
    "outputId": "34738885-85cd-424e-dcd3-42e9da72fb2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Job_title',\n",
       " 'Company',\n",
       " 'State',\n",
       " 'City',\n",
       " 'Min_Salary',\n",
       " 'Max_Salary',\n",
       " 'Job_Desc',\n",
       " 'Industry',\n",
       " 'Rating',\n",
       " 'Date_Posted',\n",
       " 'Valid_until',\n",
       " 'Job_Type']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print column informaiton here\n",
    "columns = data_job_NY.columns.tolist()\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c26eda34-205d-4a63-9182-4ac694ed19b7",
    "id": "XYL3df6mwYVU",
    "tags": []
   },
   "source": [
    "## ***Information About the columns present in the Data***\n",
    "\n",
    "1. The 12 columns in the datasets:\n",
    "    * ***Job_title*** : The title of job which you are applying to\n",
    "    * ***Company*** : Company name\n",
    "    * ***State/City*** : State/City in which the companies job posting is listed.\n",
    "    * ***Min_Salary*** : Minimum yearly salary in USD.\n",
    "    * ***Max_Salary*** : Maximum yearly salary in USD.\n",
    "    * ***Job_Desc*** : The job description which included skills,requirements,etc\n",
    "    * ***Industry*** : The industry in which the company works.\n",
    "    * ***Date_posted*** : The date  on which the job was posted on glassdoor\n",
    "    * ***Valid_until*** : The last date of applying to the job.\n",
    "    * ***Job_Type*** : Type of job full-time , part-time,etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCGGePSvwYVU"
   },
   "source": [
    "### Sorting column names\n",
    "\n",
    "You can sort the names of the columns alphabettically using the below `sorted` function\n",
    "`sorted(df)` where df is the name of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIhJlhZLwYVV"
   },
   "source": [
    "## Q6. Write the code to sort the column names alphabetically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21939,
     "status": "ok",
     "timestamp": 1605387495002,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "Rz4og9nnwYVV",
    "outputId": "54e2731d-794d-4d10-ec26-70f38aba9747"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['City',\n",
       " 'Company',\n",
       " 'Date_Posted',\n",
       " 'Industry',\n",
       " 'Job_Desc',\n",
       " 'Job_Type',\n",
       " 'Job_title',\n",
       " 'Max_Salary',\n",
       " 'Min_Salary',\n",
       " 'Rating',\n",
       " 'State',\n",
       " 'Valid_until']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using sorted() method\n",
    "sorted_columns = sorted(columns) \n",
    "sorted_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7NXIsP7wYVX"
   },
   "source": [
    "# Joining OR Concatenating Dataframes\n",
    "To join dataframes together use the panda function `concat`.\n",
    "`pd.concat(df1, df2, df3, ..., dfn)` where pd is the panda library name and df1 is dataframe1, df2 is dataframe2, and df3 is dataframe3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "a5ab06c9-3fb5-4b41-a3a2-69f22b7bca6e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 22082,
     "status": "ok",
     "timestamp": 1605387495157,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "o9J9kIxQwYVY",
    "outputId": "aa54b86b-d494-4ed3-87fb-cf8a9a937f5a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Min_Salary</th>\n",
       "      <th>Max_Salary</th>\n",
       "      <th>Job_Desc</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date_Posted</th>\n",
       "      <th>Valid_until</th>\n",
       "      <th>Job_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chief Marketing Officer (CMO)</td>\n",
       "      <td>National Debt Relief</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Who We're Looking For:\\n\\nThe Chief Marketing Officer (CMO) is an exempt, executive position, responsible for all marketing operations of the company including lead acquisition, sales enablement, communications, retention, and brand development. This executive leads a team of enthusiastic, analytical, and passionate marketing professionals to develop, execute, and optimize the marketing strategy. We are looking for someone with a history of brand development and proven ability to accelerate company growth leveraging the latest marketing strategies and technologies. This role goes beyond traditional marketing tactics to generate awareness, educate the consumer on the viability of our service, and in turn drive the consumer to take action and engage the brand.\\n\\nPrincipal Duties and Responsibilities:\\n\\nLead the full marketing strategy and have accountability over development, execution, and optimization across all channels including paid and organic search, display, email, social, TV, radio, direct mail, and affiliate marketing.\\nCommunicate with the leadership team and key stakeholders to execute lead generation, sales enablement, and retention-based marketing campaigns that align with and deliver against business goals.\\nDevelop and execute social media, content, and communication strategies to further our public relations and community engagement.\\nIdentify, forge, and grow strategic marketing partnerships.\\nBuild a highly efficient and capable team of marketing professionals.\\nDefine the competitive marketplace and evolve our brand awareness through strategy development and brand building tactics.\\nLead research and development into new marketing tactics and strategies while improving current systems.\\nEstablish key metrics and manage goals while leading the improvement of our pipeline for sales.\\nEstablish framework for all marketing activity, tracking results and reporting progress with management.\\nDevelop segmentation, competitive analysis, market intelligence, salesforce effectiveness, strategic planning and revenue retention and growth.\\n\\nQualifications:\\n\\nA completed BS degree in Business, Marketing, Advertising or other related discipline.\\nMinimum experience required 10+ years of professional experience in a leadership marketing role.\\nExperience building and executing brand awareness and public relations campaigns.\\nExperience in a fast-growing company with a track record of delivering big results.\\nHighly proficient and effective communication skills\\nAbility to utilize data analytics to deliver insight and identify opportunities for growth.\\nA strong record of developing successful, innovative and cost-effective marketing campaigns.\\nPunctual and ready to report to work on a consistent basis.\\nTravel up to 25 percent of the time.\\nExcel in a fast-paced environment.\\n\\nWhat We Offer:\\n\\nA team-first, work hard play hard culture, full of rewards and recognition for our employees. We are dedicated to our employees' success and growth.\\n\\nOur extensive benefits package includes:\\n\\n\\nGenerous Medical, Dental, and Vision Benefits\\n401(k) with Company Match\\nPaid Holidays, Volunteer Time Off, Sick Days, and Vacation\\n10 weeks Paid Parental Leave\\nPre-tax Transit Benefits\\nDiscounted Gym Membership\\nCiti Bike Annual Membership Discounts\\nNo-Cost Life Insurance Benefits\\nVoluntary Benefits Options\\nASPCA Pet Health Insurance Discount\\n\\nAbout National Debt Relief:\\n\\nNational Debt Relief is one of the country's largest and most reputable debt settlement companies. We are made up of energetic, smart, and compassionate individuals who are passionate about helping thousands of Americans with debt relief. Most importantly, we're all about helping our customers through a tough financial time in their lives with education and individual customer service.\\n\\nWe are dedicated to helping individuals and families rid their lives of burdensome debt. We specialize in debt settlement and have negotiated settlements for thousands of creditor and collections accounts. We provide our clients with both our expertise and our proven results. This means helping consumers in their time of hardship to get out of debt with the least possible cost. It can also mean conducting financial consultations, educating the consumer, and recommending the appropriate solution. Our core services offer debt settlement as an alternative to bankruptcy, credit counseling, and debt consolidation. We become our clients' number one advocate to help them reestablish financial stability as quickly as possible.\\n\\nNational Debt Relief is a certified Great Place to Work®!\\n\\nNational Debt Relief is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability status, or any other status protected by law\\n\\n#ZR</td>\n",
       "      <td>Finance</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>2020-06-07</td>\n",
       "      <td>FULL_TIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Registered Nurse</td>\n",
       "      <td>Queens Boulevard Endoscopy Center</td>\n",
       "      <td>NY</td>\n",
       "      <td>Rego Park</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Queens Boulevard Endoscopy Center, an endoscopy ASC located in Rego Park, has an exciting opportunity for Full-Time Registered Nurse! Successful candidates will provide quality nursing care in all areas of the Center including pre-assessment, pre-op and pacu  Qualified candidates must possess the following:\\n\\nCurrent NY state RN license\\nBLS Certification, ACLS preferred\\nMust be a team-player with excellent multi-tasking and interpersonal skills\\nCompassion for patient needs and a high degree of professionalism\\nChinese Speaking and Spanish Preferred\\n\\nQueens Boulevard Endoscopy Center offers a pleasant professional work environment and no evening or holiday work hours. Drug-free work environment and EOE.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020-04-25</td>\n",
       "      <td>2020-06-07</td>\n",
       "      <td>FULL_TIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dental Hygienist</td>\n",
       "      <td>Batista Dental</td>\n",
       "      <td>NJ</td>\n",
       "      <td>West New York</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Part-time or Full-timedental hygienist position available in West New York, NJfor Mondays, Tuesdays, Wednesdays, and Saturday.Applicants may apply for any or all days. Beautiful upscale office with friendly staff. Applicants must be reliable, self-motivated and speak spanish out-going and responsible. Respond with resume via e-mail.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-05-02</td>\n",
       "      <td>2020-06-07</td>\n",
       "      <td>PART_TIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Salesforce Developer</td>\n",
       "      <td>National Debt Relief</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>44587</td>\n",
       "      <td>82162</td>\n",
       "      <td>Principle Duties &amp; Responsibilities:\\n\\nAnalyze complex systems and troubleshoot and isolate system issues;\\nUnderstand requirements for business users and translate into design specifications, utilizing thorough understanding of the Salesforce platform, Salesforce products and licensing models;\\nUtilize thorough understanding of application development, project lifecycle, and methodologies and ability to work under tight deadlines and handle multiple detail-oriented tasks;\\nApply knowledge of Salesforce developmentand customizations, with APEX, Visual Force, API, Force.com and Workflows, taking into account com best practices, support mechanisms, procedures, and limitations, as well as NDR's unique needs;\\nResponsible for Salesforce administration, release management and deployment as well as management of Salesforce.com sandboxes, including their integrations;\\nDesign and execute Salesforce.com configuration changes, leveraging the Salesforce interface to sync with internal tracking systems;\\nDesign, develop, and maintain integration and synchronization programs;\\nDesign the data model, user interface, business logic, and security for custom applications; and\\nDesign, develop, and customize software solutions for end users by using analysis and mathematical models to effectively predict and measure the results of the design using Chatter, Communities and other Salesforce applications.\\n\\nRequirements:\\n\\nBachelor of Science degree or foreign equivalent in Information Systems, Computer Science, Computer Engineering, Software Engineering or a related field\\n3 years of experience with the Salesforce platform, specifically: development with Apex, VisualForce, and Force.com;\\nDesign and execute Salesforce.com configuration changes, leveraging the Salesforce interface to sync with internal tracking systems;\\nSalesforce administration, release management, and deployment\\nSalesforce products and licensing models\\nManagement of Salesforce.com sandboxes, including their integrations; Chatter, Communities, and other Salesforce apps\\ncom best practices, support mechanisms, procedures, and limitations.\\n\\nWhat We Offer:\\n\\nWe believe in a team-first culture, full of rewards and recognition for our employees. We are dedicated to our employees' success and growth within the company, through our employee mentorship and leadership programs.\\n\\nOur extensive benefits package includes:\\n\\n\\nMedical, Dental, and Vision Benefits\\n401(k) Match\\nPaid Holidays, Volunteer Time Off, Sick Days, and Vacation\\n10 Weeks Paid Parental Leave\\nPre-tax Transit Benefits\\nDiscounted Gym Membership\\nNo-cost Life Insurance Benefits\\n\\nAbout National Debt Relief:\\n\\nNational Debt Relief is one of the country's largest and most reputable debt settlement companies. We are made up of energetic, smart, and compassionate individuals who are passionate about helping thousands of Americans with debt relief. Most importantly, we're all about helping our customers through a tough financial time in their lives with education and individual customer service.\\n\\nWe are dedicated to helping individuals and families rid their lives of burdensome debt. We specialize in debt settlement and have negotiated settlements for thousands of creditor and collections accounts. We provide our clients with both our expertise and our proven results. This means helping consumers in their time of hardship to get out of debt with the least possible cost. It can also mean conducting financial consultations, educating the consumer, and recommending the appropriate solution. Our core services offer debt settlement as an alternative to bankruptcy, credit counseling, and debt consolidation. We become our clients' number one advocate to help them reestablish financial stability as quickly as possible.\\n\\n#ZR</td>\n",
       "      <td>Finance</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>2020-06-07</td>\n",
       "      <td>FULL_TIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEPUTY EXECUTIVE DIRECTOR, PROGRAM AND LEGAL ADVOCACY</td>\n",
       "      <td>National Advocates for Pregnant Women</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>125410</td>\n",
       "      <td>212901</td>\n",
       "      <td>For FULL Job Announcement, visit our website: www.AdvocatesForPregnantWomen.org\\n\\nReporting to and working collaboratively with the Executive Director (ED), the Deputy Executive Director, Program &amp; Legal Advocacy (DED) is a member of the Senior Management Team (SMT) providing leadership for and supervision of NAPW’s legal team and taking responsibility for the day-to-day program operations of the organization. The DED as an experienced senior level attorney with executive management experience and serves as a strategic thought partner and advisor to the Executive Director and the SMT.\\n\\nIn absence of the Executive Director, the DED (in consultation with the COO), is designated as the highest authority to respond to internal and external inquiries, make programmatic/advocacy decisions, and represent NAPW in any and all responsibilities assigned to the ED.\\n\\nResponsibilities include (but are not limited to):\\n\\nPartnering with the ED to create and implement NAPW’s mission-work and strategic planning;Working collaboratively with the SMT (collectively responsible for the critical business functions of Program, Finance/Operations, Human Resources, Communications, and Development/Grant Administration), to develop and implement administrative policies and procedures for guiding operations, strengthening internal systems, ensuring high levels of staff engagement, managing performance, encouraging continuous learning, and promoting administrative and programmatic alignment;Helping to create NAPW’s reproductive justice public policy/public advocacy initiatives and determining when NAPW supports and/or joins related allied efforts by other organizations;Directly supervising the day-to-day work of the Senior Staff Attorneys, Staff Attorneys, post-graduate Fellows, legal &amp; programmatic interns, legal contractors, loaned associates, and Research and Program Associates. Supervision includes coaching and training, performance review, assigning and reviewing work, mentoring, analysis and editing of written work and providing the ED with sufficient time to review;\\n\\nMinimum qualifications include:\\n\\nJD degree from an accredited law school is required; Membership in at least 1 (one) state AND federal bar is required;Master’s Degree in Non-profit Management, Public Policy, Social Work, or a related field is highly-desirable;8-10 years: of senior-level management experience in a non-profit legal advocacy/public interest/social justice environment, with demonstrable success in change implementation; complex litigation and advocacy experience as an attorney providing direct client representation, with a particular emphasis in public interest law and reproductive justice and drug policy litigation in state and federal courts; experience in the supervision of attorneys and managing programs (and staff);Demonstrated capacity to serve as a member of a Senior Management Team and advisor to the Executive Director on all matters pertaining to NAPW's legal advocacy;Knowledge of and experience in reproductive health, rights, and justice; civil rights with knowledge of drug policy reform, women’s rights, family law, child welfare reform, and human rights is highly-desirable.\\n\\nNOTE: YOUR SUBMISSION WILL BE REJECTED IF YOU HAVE NOT PROVIDED ALL MATERIALS AND INFORMATION AS INSTRUCTED BELOW.\\n\\nREQUIRED SUBMISSIONS (MUST INCLUDE ALL ITEMS LISTED BELOW):\\n\\n1. Cover Letter which must include all of the following elements:\\n\\na) Your personal &amp; professional motivation for seeking this position.\\n\\nb) A discussion of what makes you the ideal/best candidate for this position.\\n\\nc) Explain how your skill sets and experience best demonstrate your strategic approach.\\n\\nd) Salary Requirement.\\n\\ne) Indicate where you found this Job Announcement.\\n\\n2. Resumé.\\n\\n3. Two (2) Writing Samples solely reflecting applicant’s own work (MUST submit BOTH A and B):\\n\\na) One Non- legal advocacy writing sample such as an article, commentary or blog.\\n\\nb) One Legal writing sample (i.e., a legal brief, argument or analysis) consisting of NO MORE THAN ten pages of text.\\n\\n4. Complete contact information for three (3) professional references.\\n\\nINSTRUCTIONS: NO PHONE CALLS OR FAXES PLEASE.\\n\\nAll submissions must be sent VIA EMAIL ONLY\\n\\nSUBJECT: ATTN: Human Resources – NAPW Deputy Executive Director, Program &amp; Legal Advocacy (JAN. 2020)\\n\\nJob Type: Full-time\\n\\nExperience:\\n\\nReproductive Justice/Reproductive Rights legal advocacy: 5 years (Preferred)Non-profit Executive/Senior Management: 8 years (Required)Supervising Attorney: 5 years (Required)Public Interest Law and litigation: 6 years (Required)\\n\\nEducation:\\n\\nDoctorate (Required)\\n\\nWork Location:\\n\\nOne location\\n\\nBenefits:\\n\\nHealth insuranceDental insuranceVision insuranceRetirement planPaid time offParental leaveProfessional development assistanceTuition reimbursement\\n\\nSchedule:\\n\\nMonday to Friday\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>2020-06-07</td>\n",
       "      <td>FULL_TIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3319</th>\n",
       "      <td>Data Engineer/Architect with Security Clearance</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>VA</td>\n",
       "      <td>McLean</td>\n",
       "      <td>74916</td>\n",
       "      <td>128610</td>\n",
       "      <td>Job Number: R0082817 Data Engineer/Architect\\n\\nKey Role:\\n\\nSupport the collection, ingestion, storage, processing, and analysis of complex datasets to disseminate mission-critical insights to our clients. Design, architect, implement, monitor, and maintain solutions to enable increasingly complex data analytics. Integrate solutions with broader technology architecture used across the organization while influencing enterprise architecture to meet the needs of the future. Maintain the perspective of the entire client organization, mapping the systems and interfaces used to manage data, setting standards for data management, analyzing the current state and conceiving desired future state, and articulating projects needed to close the gap between the current state and future goals. Basic Qualifications: * 8+ years of experience in data modeling and database design, from conceptualization to database optimization\\n\\n\\n\\n2+ years of experience with NoSQL databases, including HBase or Cassandra * Experience with Hadoop cluster and all included services, including Hadoop v2, HDFS * Knowledge of Big Data querying tools, including Pig, Hive, or Impala * Knowledge of the system development life cycle; software project management approaches; and requirements, design, and test techniques\\nKnowledge of established and emerging data technologies; conversant in emerging tools like columnar and NoSQL databases, predictive analytics, data visualization, and unstructured data\\nAbility to obtain a security clearance\\nBA or BS degree Additional Qualifications: * Ability to explain advanced concepts to team members, users, and clients\\nAbility to work independently and address ad-hoc challenges\\nPossession of excellent communications skills\\nPossession of excellent problem-solving skills Clearance:\\n\\n\\n\\nApplicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information. We're an EOE that empowers our people-no matter their race, color, religion, sex, gender identity, sexual orientation, national origin, disability, veteran status, or other protected characteristic-to fearlessly drive change.</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2020-04-24</td>\n",
       "      <td>2020-06-06</td>\n",
       "      <td>FULL_TIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3320</th>\n",
       "      <td>Data Engineer with Security Clearance</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>VA</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>58824</td>\n",
       "      <td>112227</td>\n",
       "      <td>Job Number: R0083152 Data Engineer\\n\\nThe Challenge: Are you excited at the prospect of unlocking the secrets held by a data set? Are you fascinated by the possibilities presented by the IoT, machine learning, and artificial intelligence advances? In an increasingly connected world, massive amounts of structured and unstructured data open up new opportunities. As a data scientist, you can turn these complex data sets into useful information to solve global challenges. Across private and public sectors - from fraud detection, to cancer research, to national intelligence - you know the answers are in the data. We have an opportunity for you to use your analytical skills to improve strategic innovation for the federal government. You'll work closely with your customer to understand their questions and needs, and then dig into their data-rich environment to find the pieces of their information puzzle. You'll mentor teammates, develop algorithms, write scripts, build predictive analytics, apply machine learning, and use the right combination of tools and frameworks to turn that set of disparate data points into objective answers to help federal health organizations make informed decisions. You'll provide your customer with a deep understanding of their data, what it all means, and how they can use it. Join us as we use data science for good in the federal government. Empower change with us. You Have: -3+ years of experience within data science and engineering -2+ years of experience in working with machine learning models and algorithms, including natural language processing (NLP) -2+ years of experience with object-oriented programming, including Java, Scala, or Python -Experience with Big Data technologies, including HDFS, Hadoop, and Spark -Experience with manipulating data and extract, transform, and load (ETL) in parallel processing and distributed compute environments -Experience with using Cloud services, including AWS and Azure -Ability to learn technical concepts quickly and communicate with multiple functional groups -Secret clearance -BA or BS degree Nice If You Have: -2+ years of experience with designing novel data analytic methods and workflows, including full data pipelines from raw data through analysis results -Ability to manage and manipulate large data sets, develop data science approaches, and manage data science tasks -Ability to leverage a wide variety of data science capabilities and languages -Ability to exhibit flexibility, initiative, and innovation when dealing with ambiguous and fast-paced situations -MA or MS degree in Engineering, Statistics, Mathematics, or Data Science Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required Build Your Career: At Booz Allen, we know the power of analytics and we're dedicated to helping you grow as a data analysis professional. When you join Booz Allen, you can expect: * access to online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk\\n\\n\\n\\na chance to change the world with the Data Science Bowl-the world's premier data science for social good competition\\nparticipation in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government You'll have access to a wealth of training resources through our Analytics University, an online learning portal specifically geared towards data science and analytics skills, where you can access more than 5000 functional and technical courses, certifications, and books. Build your technical skills through hands-on training on the latest tools and state-of-the-art tech from our in-house experts. Pursuing certifications? Take advantage of our tuition assistance, onsite boot camps, certification training, academic programs, vendor relationships, and a network of professionals who can give you helpful tips. We'll help you develop the career you want, as you chart your own course for success. We're an EOE that empowers our people-no matter their race, color, religion, sex, gender identity, sexual orientation, national origin, disability, veteran status, or other protected characteristic-to fearlessly drive change. #LI-AH1, CJ1\\n</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2020-05-02</td>\n",
       "      <td>2020-06-06</td>\n",
       "      <td>FULL_TIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3321</th>\n",
       "      <td>Data Engineer, Mid with Security Clearance</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>VA</td>\n",
       "      <td>Herndon</td>\n",
       "      <td>58824</td>\n",
       "      <td>112227</td>\n",
       "      <td>Job Number: R0083073 Data Engineer, Mid\\n\\nKey Role: Leverage expertise in structured and unstructured data to perform data engineering activities on cutting-edge projects in the ind us try working with Big Data tools. Architect data systems and stand up data platforms, build out ETL pipelines, write c us tom code, interface with data stores, perform data ingestion, and build data models. Assess, design, build, and maintain scalable data platforms that us e the latest and best in Big Data tools. Perform analytical exploration and examination of data from multiple sources of data. Work in Scrum-based Agile environment with multi-disciplinary team of analysts, data engineers, data scientists, developers, and data consumers in an agile fast-paced environment that is p us hing the envelope of leading-edge Big Data implementations. Basic Qualifications: -2+ years of experience with developing ETL pipelines and developing data manipulation scripts\\n\\n\\n\\n2+ years of experience in us ing SQL, working with modern relational databases, including MySQL or PostgreSQL -2+ years of experience with Big Data systems, including Hadoop, HDFS, Hive, or Cloudera -Experience with us ing Lucene based search engines, including elasticsearch or solr\\nActive Secret clearance -BS degree in CS or Information Systems required Additional Qualifications: -Experience with Agile sof tware development -Experience with Big Data ETL tools like StreamSets and NiFi\\nExperience with AWS cloud te chn ologies -Experience in working with enterprise and production systems -Ability to have a positive, can-do attitude to solve the challenges of tomorrow -Ability to learn te chn ical concepts and communicate with multiple functional groups -Possession of excellent oral and written communication skills -Hortonworks, Cloudera, or Big data Certifications Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. We're an EOE that empowers our people-no matter their race, color, religion, sex, gender identity, sexual orientation, national origin, disability, veteran status, or other protected characteristic-to fearlessly drive change.\\n</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>2020-06-06</td>\n",
       "      <td>FULL_TIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3322</th>\n",
       "      <td>Data Modeler, Senior with Security Clearance</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>VA</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>90454</td>\n",
       "      <td>151998</td>\n",
       "      <td>Job Number: R0082912 Data Modeler, Senior\\n\\nThe Challenge: Are you excited at the prospect of unlocking the secrets held by a data set? Are you fascinated by the possibilities presented by the IoT, machine learning, and artificial intelligence advances? In an increasingly connected world, massive amounts of structured and unstructured data open up new opportunities. As a data scientist, you can turn these complex data sets into useful information to solve global challenges. Across private and public sectors - from fraud detection, to cancer research, to national intelligence - you know the answers are in the data. We have an opportunity for you to use your leadership and analytical skills to improve a department of defense client. You'll work closely with your customer to understand their questions and needs, and then dig into their data-rich environment to find the pieces of their information puzzle. You'll mentor teammates, develop algorithms, write scripts to develop workflows, build predictive analytics, use automation, apply machine learning, and use the right combination of tools and frameworks to turn that set of disparate data points into objective answers to help senior leadership make informed decisions. You'll provide your customer with a deep understanding of their data, what it all means, and how they can use it. Join us as we use data science for good in national security. Empower change with us. You Have: * Experience with using data science tools * Experience with data modeling, building workflows, and tasking * Experience with Python to perform data analysis, mining, and data visualization * Knowledge of JEMA * Ability to create mathematical and statistical models * TS/SCI clearance with a polygraph * BA or BS degree or 10 years of experience with analytics Nice If You Have: * Experience with machine learning * Knowledge of GEOINT TCPED * Knowledge of GEOINT tools * MA or MS degree Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required. Build Your Career: At Booz Allen, we know the power of analytics and we're dedicated to helping you grow as a data analysis professional. When you join Booz Allen, you'll have the chance to: * access online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk\\n\\n\\n\\nchange the world with the Data Science Bowl-the world's premier data science for social good competition\\nparticipate in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government You'll have access to a wealth of training resources through our Analytics University, an online learning portal specifically geared towards data science and analytics skills, where you can access more than 5000 functional and technical courses, certifications, and books. Build your technical skills through hands-on training on the latest tools and state-of-the-art tech from our in-house experts. Pursuing certifications that directly impact your role? You may be able to take advantage of our tuition assistance, on-site bootcamps, certification training, academic programs, vendor relationships, and a network of professionals who can give you helpful tips. We'll help you develop the career you want as you chart your own course for success. We're an EOE that empowers our people-no matter their race, color, religion, sex, gender identity, sexual orientation, national origin, disability, veteran status, or other protected characteristic-to fearlessly drive change.\\n</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>2020-06-06</td>\n",
       "      <td>FULL_TIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3323</th>\n",
       "      <td>Data Engineer, Senior with Security Clearance</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>VA</td>\n",
       "      <td>Herndon</td>\n",
       "      <td>91443</td>\n",
       "      <td>155868</td>\n",
       "      <td>Job Number: R0083334 Data Engineer, Senior\\n\\nKey Role: Develop data pipelines us ing Big Data services available in the Cloud. Architect data repositories, stand up data platforms, and write c us tom code for data ingestion, transformation, and aggregation. Create data models to support b us iness requirements. Work as a client-facing consultant providing solutions to Big Data us e cases. Develop continuo us integration ( CI ) and continuo us delivery ( CD ) pipelines to support automated deployment and automated testing. Basic Qualifications: -6+ years of experience with a modern programming language, including Python or Java -4+ years of experience with working in an agile development environment -4+ years of experience with developing extract, transform, load ( ETL ) and data pipelines -3+ years of experience with SQL -2+ years of experience with working in a Big Data environment -Ability to learn te chn ical concepts -Secret clearance -BA or BS degree Additional Qualifications: -Experience with Cloudera or Hortonworks -Experience with Hadoop ecosystem -Experience with data modeling concepts -Experience with leading a te chn ical team -Possession of excellent analytical and problem-solving skills -Possession of excellent oral and written communication skills, including communicating with multiple functional groups Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. We're an EOE that empowers our people-no matter their race, color, religion, sex, gender identity, sexual orientation, national origin, disability, veteran status, or other protected characteristic-to fearlessly drive change.</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2020-05-02</td>\n",
       "      <td>2020-06-06</td>\n",
       "      <td>FULL_TIME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3324 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Job_title  ...   Job_Type\n",
       "0     Chief Marketing Officer (CMO)                          ...  FULL_TIME\n",
       "1     Registered Nurse                                       ...  FULL_TIME\n",
       "2     Dental Hygienist                                       ...  PART_TIME\n",
       "3     Senior Salesforce Developer                            ...  FULL_TIME\n",
       "4     DEPUTY EXECUTIVE DIRECTOR, PROGRAM AND LEGAL ADVOCACY  ...  FULL_TIME\n",
       "...                                                     ...  ...        ...\n",
       "3319  Data Engineer/Architect with Security Clearance        ...  FULL_TIME\n",
       "3320  Data Engineer with Security Clearance                  ...  FULL_TIME\n",
       "3321  Data Engineer, Mid with Security Clearance             ...  FULL_TIME\n",
       "3322  Data Modeler, Senior with Security Clearance           ...  FULL_TIME\n",
       "3323  Data Engineer, Senior with Security Clearance          ...  FULL_TIME\n",
       "\n",
       "[3324 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Below is an example of how to concatenate the dataframes together\n",
    "#Concatenating the data files\n",
    "\n",
    "all_df = pd.concat([data_job_NY , data_job_SF , data_job_TX, data_job_WA] , axis = 0 , ignore_index = True)\n",
    "all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JiFZUNqBwYVa"
   },
   "source": [
    "# Garbage Collection\n",
    "In some cases you should perform garbage collection to clear up your workspace\n",
    "This is especially true when working on cloud-based systems like Collab or Jupyter notebooks\n",
    "\n",
    "Use the `gc.collect()` function to clean up any dataframes that you don't need anymore\n",
    "To do this you'll need to delete them first then call `gc.collect()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "cell_id": "4a80b5b4-163d-4e4b-a243-2bf4ee8b890b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22230,
     "status": "ok",
     "timestamp": 1605387495316,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "v1O8AGbxwYVa",
    "outputId": "2c8a4483-44f7-4367-db6b-1b1f55f6fb46",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data_job_NY, data_job_SF, data_job_TX, data_job_WA\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdQOUAX_wYVc"
   },
   "source": [
    "## Q7. Write the output from the collect function below\n",
    "\n",
    "516\n",
    "\n",
    "## Q8. What do you think it means?\n",
    "\n",
    "It is the number of unreachable objects by the garbage collector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "3c7fd77a-44b2-4e40-9263-99e82b635903",
    "id": "6tGmgwVvwYVd",
    "tags": []
   },
   "source": [
    "# Beginning Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hcKVJ34owYVd"
   },
   "source": [
    "## Q9. How many rows and columns does your all_df have? Write the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "e59071bd-25f5-40ed-9ee5-adb9e7139db3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22220,
     "status": "ok",
     "timestamp": 1605387495317,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "65w9MxhtwYVe",
    "outputId": "afe3d03a-b62b-4408-9004-efd1d6073bde",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3324, 12)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WRITE CODE HERE\n",
    "all_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "e9742998-e646-41fb-a082-a3f2c30369cc",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22211,
     "status": "ok",
     "timestamp": 1605387495318,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "gHiUIgBdwYVg",
    "outputId": "1ecbf33c-468b-48e4-fbc2-79fb98c92a9f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3324 entries, 0 to 3323\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Job_title    3324 non-null   object \n",
      " 1   Company      3324 non-null   object \n",
      " 2   State        3322 non-null   object \n",
      " 3   City         3318 non-null   object \n",
      " 4   Min_Salary   3324 non-null   int64  \n",
      " 5   Max_Salary   3324 non-null   int64  \n",
      " 6   Job_Desc     3324 non-null   object \n",
      " 7   Industry     2700 non-null   object \n",
      " 8   Rating       2849 non-null   float64\n",
      " 9   Date_Posted  3324 non-null   object \n",
      " 10  Valid_until  3324 non-null   object \n",
      " 11  Job_Type     3324 non-null   object \n",
      "dtypes: float64(1), int64(2), object(9)\n",
      "memory usage: 311.8+ KB\n"
     ]
    }
   ],
   "source": [
    "all_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbRzJJunwYVh"
   },
   "source": [
    "# Working with Data to Sort and Filter it\n",
    "\n",
    "Sometimes the data you are given or that you have scraped will need to be converted to another format. \n",
    "\n",
    "In all_df, we'll mainly we working with min_salary and max_salary\n",
    "\n",
    "To work with these values we'll need to convert them to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "3d2158e1-6eff-4fd3-bef5-53320e36eb26",
    "executionInfo": {
     "elapsed": 22203,
     "status": "ok",
     "timestamp": 1605387495319,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "4DMbOII4wYVi",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#First let's convert min_salary and max_salary columns to int\n",
    "all_df['Min_Salary'] = all_df['Min_Salary'].apply(lambda x : int(x))\n",
    "all_df['Max_Salary'] = all_df['Max_Salary'].apply(lambda x : int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHajZ5n9wYVk"
   },
   "source": [
    "# Working with Dates in Datasets\n",
    "Many datasets have dates within them\n",
    "To work with dates, and to sort and filter them properly you may need to work with only the month\n",
    "or only the year or only the day.\n",
    "\n",
    "Use the `calendar` library as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "6ee4f7e1-c616-4880-82a7-419ab8c46232",
    "executionInfo": {
     "elapsed": 22359,
     "status": "ok",
     "timestamp": 1605387495482,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "xWfdJAMDwYVl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Extracting date and day from Date_Posted : data is the format y-m-d\n",
    "import calendar\n",
    "all_df['Month'] = all_df['Date_Posted'].apply(lambda x : calendar.month_abbr[int(str(x).split('-')[1])]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEOb4fpkwYVn"
   },
   "source": [
    "## Q10 Write the code to extract the date and day from Valid Until column. \n",
    "data is the format y-m-d\n",
    "Name it `all_df['Valid_Month']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 22353,
     "status": "ok",
     "timestamp": 1605387495483,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "iZs0Z5WhwYVn"
   },
   "outputs": [],
   "source": [
    "all_df[\"Valid_Month\"] = all_df[\"Valid_until\"].apply(lambda x : calendar.month_abbr[int(str(x).split('-')[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nqp9rzE_wYVp"
   },
   "source": [
    "## Converting Dates to Day\n",
    "Sometimes you will need to convert a date into a given day\n",
    "To do this, you can use the function created below called \n",
    "`Convert_to_Day`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "d0556fcb-efdd-43d5-b752-515983645740",
    "executionInfo": {
     "elapsed": 22347,
     "status": "ok",
     "timestamp": 1605387495483,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "hKhhW0AmwYVp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Convert_to_Day(x):\n",
    "    sl = x.split('-')\n",
    "    \n",
    "    return calendar.day_abbr[int(calendar.weekday(int(sl[0]) , int(sl[1]) , int(sl[2])))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ryWz55ORwYVr"
   },
   "source": [
    "## Q11. Use the Convert to Day function to convert the Date_Posted and Valid_Until values to days\n",
    "Print out row 105 in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 22487,
     "status": "ok",
     "timestamp": 1605387495632,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "CXyf7NAJwYVr",
    "outputId": "b00eb092-2152-48d5-f293-4fff53b7df36"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Min_Salary</th>\n",
       "      <th>Max_Salary</th>\n",
       "      <th>Job_Desc</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date_Posted</th>\n",
       "      <th>Valid_until</th>\n",
       "      <th>Job_Type</th>\n",
       "      <th>Month</th>\n",
       "      <th>Valid_Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Vday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chief Marketing Officer (CMO)</td>\n",
       "      <td>National Debt Relief</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Who We're Looking For:\\n\\nThe Chief Marketing Officer (CMO) is an exempt, executive position, responsible for all marketing operations of the company including lead acquisition, sales enablement, communications, retention, and brand development. This executive leads a team of enthusiastic, analytical, and passionate marketing professionals to develop, execute, and optimize the marketing strategy. We are looking for someone with a history of brand development and proven ability to accelerate company growth leveraging the latest marketing strategies and technologies. This role goes beyond traditional marketing tactics to generate awareness, educate the consumer on the viability of our service, and in turn drive the consumer to take action and engage the brand.\\n\\nPrincipal Duties and Responsibilities:\\n\\nLead the full marketing strategy and have accountability over development, execution, and optimization across all channels including paid and organic search, display, email, social, TV, radio, direct mail, and affiliate marketing.\\nCommunicate with the leadership team and key stakeholders to execute lead generation, sales enablement, and retention-based marketing campaigns that align with and deliver against business goals.\\nDevelop and execute social media, content, and communication strategies to further our public relations and community engagement.\\nIdentify, forge, and grow strategic marketing partnerships.\\nBuild a highly efficient and capable team of marketing professionals.\\nDefine the competitive marketplace and evolve our brand awareness through strategy development and brand building tactics.\\nLead research and development into new marketing tactics and strategies while improving current systems.\\nEstablish key metrics and manage goals while leading the improvement of our pipeline for sales.\\nEstablish framework for all marketing activity, tracking results and reporting progress with management.\\nDevelop segmentation, competitive analysis, market intelligence, salesforce effectiveness, strategic planning and revenue retention and growth.\\n\\nQualifications:\\n\\nA completed BS degree in Business, Marketing, Advertising or other related discipline.\\nMinimum experience required 10+ years of professional experience in a leadership marketing role.\\nExperience building and executing brand awareness and public relations campaigns.\\nExperience in a fast-growing company with a track record of delivering big results.\\nHighly proficient and effective communication skills\\nAbility to utilize data analytics to deliver insight and identify opportunities for growth.\\nA strong record of developing successful, innovative and cost-effective marketing campaigns.\\nPunctual and ready to report to work on a consistent basis.\\nTravel up to 25 percent of the time.\\nExcel in a fast-paced environment.\\n\\nWhat We Offer:\\n\\nA team-first, work hard play hard culture, full of rewards and recognition for our employees. We are dedicated to our employees' success and growth.\\n\\nOur extensive benefits package includes:\\n\\n\\nGenerous Medical, Dental, and Vision Benefits\\n401(k) with Company Match\\nPaid Holidays, Volunteer Time Off, Sick Days, and Vacation\\n10 weeks Paid Parental Leave\\nPre-tax Transit Benefits\\nDiscounted Gym Membership\\nCiti Bike Annual Membership Discounts\\nNo-Cost Life Insurance Benefits\\nVoluntary Benefits Options\\nASPCA Pet Health Insurance Discount\\n\\nAbout National Debt Relief:\\n\\nNational Debt Relief is one of the country's largest and most reputable debt settlement companies. We are made up of energetic, smart, and compassionate individuals who are passionate about helping thousands of Americans with debt relief. Most importantly, we're all about helping our customers through a tough financial time in their lives with education and individual customer service.\\n\\nWe are dedicated to helping individuals and families rid their lives of burdensome debt. We specialize in debt settlement and have negotiated settlements for thousands of creditor and collections accounts. We provide our clients with both our expertise and our proven results. This means helping consumers in their time of hardship to get out of debt with the least possible cost. It can also mean conducting financial consultations, educating the consumer, and recommending the appropriate solution. Our core services offer debt settlement as an alternative to bankruptcy, credit counseling, and debt consolidation. We become our clients' number one advocate to help them reestablish financial stability as quickly as possible.\\n\\nNational Debt Relief is a certified Great Place to Work®!\\n\\nNational Debt Relief is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability status, or any other status protected by law\\n\\n#ZR</td>\n",
       "      <td>Finance</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>2020-06-07</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>May</td>\n",
       "      <td>Jun</td>\n",
       "      <td>Fri</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Registered Nurse</td>\n",
       "      <td>Queens Boulevard Endoscopy Center</td>\n",
       "      <td>NY</td>\n",
       "      <td>Rego Park</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Queens Boulevard Endoscopy Center, an endoscopy ASC located in Rego Park, has an exciting opportunity for Full-Time Registered Nurse! Successful candidates will provide quality nursing care in all areas of the Center including pre-assessment, pre-op and pacu  Qualified candidates must possess the following:\\n\\nCurrent NY state RN license\\nBLS Certification, ACLS preferred\\nMust be a team-player with excellent multi-tasking and interpersonal skills\\nCompassion for patient needs and a high degree of professionalism\\nChinese Speaking and Spanish Preferred\\n\\nQueens Boulevard Endoscopy Center offers a pleasant professional work environment and no evening or holiday work hours. Drug-free work environment and EOE.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020-04-25</td>\n",
       "      <td>2020-06-07</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Jun</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dental Hygienist</td>\n",
       "      <td>Batista Dental</td>\n",
       "      <td>NJ</td>\n",
       "      <td>West New York</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Part-time or Full-timedental hygienist position available in West New York, NJfor Mondays, Tuesdays, Wednesdays, and Saturday.Applicants may apply for any or all days. Beautiful upscale office with friendly staff. Applicants must be reliable, self-motivated and speak spanish out-going and responsible. Respond with resume via e-mail.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-05-02</td>\n",
       "      <td>2020-06-07</td>\n",
       "      <td>PART_TIME</td>\n",
       "      <td>May</td>\n",
       "      <td>Jun</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Salesforce Developer</td>\n",
       "      <td>National Debt Relief</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>44587</td>\n",
       "      <td>82162</td>\n",
       "      <td>Principle Duties &amp; Responsibilities:\\n\\nAnalyze complex systems and troubleshoot and isolate system issues;\\nUnderstand requirements for business users and translate into design specifications, utilizing thorough understanding of the Salesforce platform, Salesforce products and licensing models;\\nUtilize thorough understanding of application development, project lifecycle, and methodologies and ability to work under tight deadlines and handle multiple detail-oriented tasks;\\nApply knowledge of Salesforce developmentand customizations, with APEX, Visual Force, API, Force.com and Workflows, taking into account com best practices, support mechanisms, procedures, and limitations, as well as NDR's unique needs;\\nResponsible for Salesforce administration, release management and deployment as well as management of Salesforce.com sandboxes, including their integrations;\\nDesign and execute Salesforce.com configuration changes, leveraging the Salesforce interface to sync with internal tracking systems;\\nDesign, develop, and maintain integration and synchronization programs;\\nDesign the data model, user interface, business logic, and security for custom applications; and\\nDesign, develop, and customize software solutions for end users by using analysis and mathematical models to effectively predict and measure the results of the design using Chatter, Communities and other Salesforce applications.\\n\\nRequirements:\\n\\nBachelor of Science degree or foreign equivalent in Information Systems, Computer Science, Computer Engineering, Software Engineering or a related field\\n3 years of experience with the Salesforce platform, specifically: development with Apex, VisualForce, and Force.com;\\nDesign and execute Salesforce.com configuration changes, leveraging the Salesforce interface to sync with internal tracking systems;\\nSalesforce administration, release management, and deployment\\nSalesforce products and licensing models\\nManagement of Salesforce.com sandboxes, including their integrations; Chatter, Communities, and other Salesforce apps\\ncom best practices, support mechanisms, procedures, and limitations.\\n\\nWhat We Offer:\\n\\nWe believe in a team-first culture, full of rewards and recognition for our employees. We are dedicated to our employees' success and growth within the company, through our employee mentorship and leadership programs.\\n\\nOur extensive benefits package includes:\\n\\n\\nMedical, Dental, and Vision Benefits\\n401(k) Match\\nPaid Holidays, Volunteer Time Off, Sick Days, and Vacation\\n10 Weeks Paid Parental Leave\\nPre-tax Transit Benefits\\nDiscounted Gym Membership\\nNo-cost Life Insurance Benefits\\n\\nAbout National Debt Relief:\\n\\nNational Debt Relief is one of the country's largest and most reputable debt settlement companies. We are made up of energetic, smart, and compassionate individuals who are passionate about helping thousands of Americans with debt relief. Most importantly, we're all about helping our customers through a tough financial time in their lives with education and individual customer service.\\n\\nWe are dedicated to helping individuals and families rid their lives of burdensome debt. We specialize in debt settlement and have negotiated settlements for thousands of creditor and collections accounts. We provide our clients with both our expertise and our proven results. This means helping consumers in their time of hardship to get out of debt with the least possible cost. It can also mean conducting financial consultations, educating the consumer, and recommending the appropriate solution. Our core services offer debt settlement as an alternative to bankruptcy, credit counseling, and debt consolidation. We become our clients' number one advocate to help them reestablish financial stability as quickly as possible.\\n\\n#ZR</td>\n",
       "      <td>Finance</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>2020-06-07</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>May</td>\n",
       "      <td>Jun</td>\n",
       "      <td>Fri</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEPUTY EXECUTIVE DIRECTOR, PROGRAM AND LEGAL ADVOCACY</td>\n",
       "      <td>National Advocates for Pregnant Women</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>125410</td>\n",
       "      <td>212901</td>\n",
       "      <td>For FULL Job Announcement, visit our website: www.AdvocatesForPregnantWomen.org\\n\\nReporting to and working collaboratively with the Executive Director (ED), the Deputy Executive Director, Program &amp; Legal Advocacy (DED) is a member of the Senior Management Team (SMT) providing leadership for and supervision of NAPW’s legal team and taking responsibility for the day-to-day program operations of the organization. The DED as an experienced senior level attorney with executive management experience and serves as a strategic thought partner and advisor to the Executive Director and the SMT.\\n\\nIn absence of the Executive Director, the DED (in consultation with the COO), is designated as the highest authority to respond to internal and external inquiries, make programmatic/advocacy decisions, and represent NAPW in any and all responsibilities assigned to the ED.\\n\\nResponsibilities include (but are not limited to):\\n\\nPartnering with the ED to create and implement NAPW’s mission-work and strategic planning;Working collaboratively with the SMT (collectively responsible for the critical business functions of Program, Finance/Operations, Human Resources, Communications, and Development/Grant Administration), to develop and implement administrative policies and procedures for guiding operations, strengthening internal systems, ensuring high levels of staff engagement, managing performance, encouraging continuous learning, and promoting administrative and programmatic alignment;Helping to create NAPW’s reproductive justice public policy/public advocacy initiatives and determining when NAPW supports and/or joins related allied efforts by other organizations;Directly supervising the day-to-day work of the Senior Staff Attorneys, Staff Attorneys, post-graduate Fellows, legal &amp; programmatic interns, legal contractors, loaned associates, and Research and Program Associates. Supervision includes coaching and training, performance review, assigning and reviewing work, mentoring, analysis and editing of written work and providing the ED with sufficient time to review;\\n\\nMinimum qualifications include:\\n\\nJD degree from an accredited law school is required; Membership in at least 1 (one) state AND federal bar is required;Master’s Degree in Non-profit Management, Public Policy, Social Work, or a related field is highly-desirable;8-10 years: of senior-level management experience in a non-profit legal advocacy/public interest/social justice environment, with demonstrable success in change implementation; complex litigation and advocacy experience as an attorney providing direct client representation, with a particular emphasis in public interest law and reproductive justice and drug policy litigation in state and federal courts; experience in the supervision of attorneys and managing programs (and staff);Demonstrated capacity to serve as a member of a Senior Management Team and advisor to the Executive Director on all matters pertaining to NAPW's legal advocacy;Knowledge of and experience in reproductive health, rights, and justice; civil rights with knowledge of drug policy reform, women’s rights, family law, child welfare reform, and human rights is highly-desirable.\\n\\nNOTE: YOUR SUBMISSION WILL BE REJECTED IF YOU HAVE NOT PROVIDED ALL MATERIALS AND INFORMATION AS INSTRUCTED BELOW.\\n\\nREQUIRED SUBMISSIONS (MUST INCLUDE ALL ITEMS LISTED BELOW):\\n\\n1. Cover Letter which must include all of the following elements:\\n\\na) Your personal &amp; professional motivation for seeking this position.\\n\\nb) A discussion of what makes you the ideal/best candidate for this position.\\n\\nc) Explain how your skill sets and experience best demonstrate your strategic approach.\\n\\nd) Salary Requirement.\\n\\ne) Indicate where you found this Job Announcement.\\n\\n2. Resumé.\\n\\n3. Two (2) Writing Samples solely reflecting applicant’s own work (MUST submit BOTH A and B):\\n\\na) One Non- legal advocacy writing sample such as an article, commentary or blog.\\n\\nb) One Legal writing sample (i.e., a legal brief, argument or analysis) consisting of NO MORE THAN ten pages of text.\\n\\n4. Complete contact information for three (3) professional references.\\n\\nINSTRUCTIONS: NO PHONE CALLS OR FAXES PLEASE.\\n\\nAll submissions must be sent VIA EMAIL ONLY\\n\\nSUBJECT: ATTN: Human Resources – NAPW Deputy Executive Director, Program &amp; Legal Advocacy (JAN. 2020)\\n\\nJob Type: Full-time\\n\\nExperience:\\n\\nReproductive Justice/Reproductive Rights legal advocacy: 5 years (Preferred)Non-profit Executive/Senior Management: 8 years (Required)Supervising Attorney: 5 years (Required)Public Interest Law and litigation: 6 years (Required)\\n\\nEducation:\\n\\nDoctorate (Required)\\n\\nWork Location:\\n\\nOne location\\n\\nBenefits:\\n\\nHealth insuranceDental insuranceVision insuranceRetirement planPaid time offParental leaveProfessional development assistanceTuition reimbursement\\n\\nSchedule:\\n\\nMonday to Friday\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>2020-06-07</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Jun</td>\n",
       "      <td>Tue</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3319</th>\n",
       "      <td>Data Engineer/Architect with Security Clearance</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>VA</td>\n",
       "      <td>McLean</td>\n",
       "      <td>74916</td>\n",
       "      <td>128610</td>\n",
       "      <td>Job Number: R0082817 Data Engineer/Architect\\n\\nKey Role:\\n\\nSupport the collection, ingestion, storage, processing, and analysis of complex datasets to disseminate mission-critical insights to our clients. Design, architect, implement, monitor, and maintain solutions to enable increasingly complex data analytics. Integrate solutions with broader technology architecture used across the organization while influencing enterprise architecture to meet the needs of the future. Maintain the perspective of the entire client organization, mapping the systems and interfaces used to manage data, setting standards for data management, analyzing the current state and conceiving desired future state, and articulating projects needed to close the gap between the current state and future goals. Basic Qualifications: * 8+ years of experience in data modeling and database design, from conceptualization to database optimization\\n\\n\\n\\n2+ years of experience with NoSQL databases, including HBase or Cassandra * Experience with Hadoop cluster and all included services, including Hadoop v2, HDFS * Knowledge of Big Data querying tools, including Pig, Hive, or Impala * Knowledge of the system development life cycle; software project management approaches; and requirements, design, and test techniques\\nKnowledge of established and emerging data technologies; conversant in emerging tools like columnar and NoSQL databases, predictive analytics, data visualization, and unstructured data\\nAbility to obtain a security clearance\\nBA or BS degree Additional Qualifications: * Ability to explain advanced concepts to team members, users, and clients\\nAbility to work independently and address ad-hoc challenges\\nPossession of excellent communications skills\\nPossession of excellent problem-solving skills Clearance:\\n\\n\\n\\nApplicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information. We're an EOE that empowers our people-no matter their race, color, religion, sex, gender identity, sexual orientation, national origin, disability, veteran status, or other protected characteristic-to fearlessly drive change.</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2020-04-24</td>\n",
       "      <td>2020-06-06</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Jun</td>\n",
       "      <td>Fri</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3320</th>\n",
       "      <td>Data Engineer with Security Clearance</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>VA</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>58824</td>\n",
       "      <td>112227</td>\n",
       "      <td>Job Number: R0083152 Data Engineer\\n\\nThe Challenge: Are you excited at the prospect of unlocking the secrets held by a data set? Are you fascinated by the possibilities presented by the IoT, machine learning, and artificial intelligence advances? In an increasingly connected world, massive amounts of structured and unstructured data open up new opportunities. As a data scientist, you can turn these complex data sets into useful information to solve global challenges. Across private and public sectors - from fraud detection, to cancer research, to national intelligence - you know the answers are in the data. We have an opportunity for you to use your analytical skills to improve strategic innovation for the federal government. You'll work closely with your customer to understand their questions and needs, and then dig into their data-rich environment to find the pieces of their information puzzle. You'll mentor teammates, develop algorithms, write scripts, build predictive analytics, apply machine learning, and use the right combination of tools and frameworks to turn that set of disparate data points into objective answers to help federal health organizations make informed decisions. You'll provide your customer with a deep understanding of their data, what it all means, and how they can use it. Join us as we use data science for good in the federal government. Empower change with us. You Have: -3+ years of experience within data science and engineering -2+ years of experience in working with machine learning models and algorithms, including natural language processing (NLP) -2+ years of experience with object-oriented programming, including Java, Scala, or Python -Experience with Big Data technologies, including HDFS, Hadoop, and Spark -Experience with manipulating data and extract, transform, and load (ETL) in parallel processing and distributed compute environments -Experience with using Cloud services, including AWS and Azure -Ability to learn technical concepts quickly and communicate with multiple functional groups -Secret clearance -BA or BS degree Nice If You Have: -2+ years of experience with designing novel data analytic methods and workflows, including full data pipelines from raw data through analysis results -Ability to manage and manipulate large data sets, develop data science approaches, and manage data science tasks -Ability to leverage a wide variety of data science capabilities and languages -Ability to exhibit flexibility, initiative, and innovation when dealing with ambiguous and fast-paced situations -MA or MS degree in Engineering, Statistics, Mathematics, or Data Science Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required Build Your Career: At Booz Allen, we know the power of analytics and we're dedicated to helping you grow as a data analysis professional. When you join Booz Allen, you can expect: * access to online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk\\n\\n\\n\\na chance to change the world with the Data Science Bowl-the world's premier data science for social good competition\\nparticipation in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government You'll have access to a wealth of training resources through our Analytics University, an online learning portal specifically geared towards data science and analytics skills, where you can access more than 5000 functional and technical courses, certifications, and books. Build your technical skills through hands-on training on the latest tools and state-of-the-art tech from our in-house experts. Pursuing certifications? Take advantage of our tuition assistance, onsite boot camps, certification training, academic programs, vendor relationships, and a network of professionals who can give you helpful tips. We'll help you develop the career you want, as you chart your own course for success. We're an EOE that empowers our people-no matter their race, color, religion, sex, gender identity, sexual orientation, national origin, disability, veteran status, or other protected characteristic-to fearlessly drive change. #LI-AH1, CJ1\\n</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2020-05-02</td>\n",
       "      <td>2020-06-06</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>May</td>\n",
       "      <td>Jun</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3321</th>\n",
       "      <td>Data Engineer, Mid with Security Clearance</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>VA</td>\n",
       "      <td>Herndon</td>\n",
       "      <td>58824</td>\n",
       "      <td>112227</td>\n",
       "      <td>Job Number: R0083073 Data Engineer, Mid\\n\\nKey Role: Leverage expertise in structured and unstructured data to perform data engineering activities on cutting-edge projects in the ind us try working with Big Data tools. Architect data systems and stand up data platforms, build out ETL pipelines, write c us tom code, interface with data stores, perform data ingestion, and build data models. Assess, design, build, and maintain scalable data platforms that us e the latest and best in Big Data tools. Perform analytical exploration and examination of data from multiple sources of data. Work in Scrum-based Agile environment with multi-disciplinary team of analysts, data engineers, data scientists, developers, and data consumers in an agile fast-paced environment that is p us hing the envelope of leading-edge Big Data implementations. Basic Qualifications: -2+ years of experience with developing ETL pipelines and developing data manipulation scripts\\n\\n\\n\\n2+ years of experience in us ing SQL, working with modern relational databases, including MySQL or PostgreSQL -2+ years of experience with Big Data systems, including Hadoop, HDFS, Hive, or Cloudera -Experience with us ing Lucene based search engines, including elasticsearch or solr\\nActive Secret clearance -BS degree in CS or Information Systems required Additional Qualifications: -Experience with Agile sof tware development -Experience with Big Data ETL tools like StreamSets and NiFi\\nExperience with AWS cloud te chn ologies -Experience in working with enterprise and production systems -Ability to have a positive, can-do attitude to solve the challenges of tomorrow -Ability to learn te chn ical concepts and communicate with multiple functional groups -Possession of excellent oral and written communication skills -Hortonworks, Cloudera, or Big data Certifications Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. We're an EOE that empowers our people-no matter their race, color, religion, sex, gender identity, sexual orientation, national origin, disability, veteran status, or other protected characteristic-to fearlessly drive change.\\n</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>2020-06-06</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>May</td>\n",
       "      <td>Jun</td>\n",
       "      <td>Thu</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3322</th>\n",
       "      <td>Data Modeler, Senior with Security Clearance</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>VA</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>90454</td>\n",
       "      <td>151998</td>\n",
       "      <td>Job Number: R0082912 Data Modeler, Senior\\n\\nThe Challenge: Are you excited at the prospect of unlocking the secrets held by a data set? Are you fascinated by the possibilities presented by the IoT, machine learning, and artificial intelligence advances? In an increasingly connected world, massive amounts of structured and unstructured data open up new opportunities. As a data scientist, you can turn these complex data sets into useful information to solve global challenges. Across private and public sectors - from fraud detection, to cancer research, to national intelligence - you know the answers are in the data. We have an opportunity for you to use your leadership and analytical skills to improve a department of defense client. You'll work closely with your customer to understand their questions and needs, and then dig into their data-rich environment to find the pieces of their information puzzle. You'll mentor teammates, develop algorithms, write scripts to develop workflows, build predictive analytics, use automation, apply machine learning, and use the right combination of tools and frameworks to turn that set of disparate data points into objective answers to help senior leadership make informed decisions. You'll provide your customer with a deep understanding of their data, what it all means, and how they can use it. Join us as we use data science for good in national security. Empower change with us. You Have: * Experience with using data science tools * Experience with data modeling, building workflows, and tasking * Experience with Python to perform data analysis, mining, and data visualization * Knowledge of JEMA * Ability to create mathematical and statistical models * TS/SCI clearance with a polygraph * BA or BS degree or 10 years of experience with analytics Nice If You Have: * Experience with machine learning * Knowledge of GEOINT TCPED * Knowledge of GEOINT tools * MA or MS degree Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required. Build Your Career: At Booz Allen, we know the power of analytics and we're dedicated to helping you grow as a data analysis professional. When you join Booz Allen, you'll have the chance to: * access online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk\\n\\n\\n\\nchange the world with the Data Science Bowl-the world's premier data science for social good competition\\nparticipate in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government You'll have access to a wealth of training resources through our Analytics University, an online learning portal specifically geared towards data science and analytics skills, where you can access more than 5000 functional and technical courses, certifications, and books. Build your technical skills through hands-on training on the latest tools and state-of-the-art tech from our in-house experts. Pursuing certifications that directly impact your role? You may be able to take advantage of our tuition assistance, on-site bootcamps, certification training, academic programs, vendor relationships, and a network of professionals who can give you helpful tips. We'll help you develop the career you want as you chart your own course for success. We're an EOE that empowers our people-no matter their race, color, religion, sex, gender identity, sexual orientation, national origin, disability, veteran status, or other protected characteristic-to fearlessly drive change.\\n</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>2020-06-06</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Jun</td>\n",
       "      <td>Tue</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3323</th>\n",
       "      <td>Data Engineer, Senior with Security Clearance</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>VA</td>\n",
       "      <td>Herndon</td>\n",
       "      <td>91443</td>\n",
       "      <td>155868</td>\n",
       "      <td>Job Number: R0083334 Data Engineer, Senior\\n\\nKey Role: Develop data pipelines us ing Big Data services available in the Cloud. Architect data repositories, stand up data platforms, and write c us tom code for data ingestion, transformation, and aggregation. Create data models to support b us iness requirements. Work as a client-facing consultant providing solutions to Big Data us e cases. Develop continuo us integration ( CI ) and continuo us delivery ( CD ) pipelines to support automated deployment and automated testing. Basic Qualifications: -6+ years of experience with a modern programming language, including Python or Java -4+ years of experience with working in an agile development environment -4+ years of experience with developing extract, transform, load ( ETL ) and data pipelines -3+ years of experience with SQL -2+ years of experience with working in a Big Data environment -Ability to learn te chn ical concepts -Secret clearance -BA or BS degree Additional Qualifications: -Experience with Cloudera or Hortonworks -Experience with Hadoop ecosystem -Experience with data modeling concepts -Experience with leading a te chn ical team -Possession of excellent analytical and problem-solving skills -Possession of excellent oral and written communication skills, including communicating with multiple functional groups Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. We're an EOE that empowers our people-no matter their race, color, religion, sex, gender identity, sexual orientation, national origin, disability, veteran status, or other protected characteristic-to fearlessly drive change.</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2020-05-02</td>\n",
       "      <td>2020-06-06</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>May</td>\n",
       "      <td>Jun</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3324 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Job_title  ... Vday\n",
       "0     Chief Marketing Officer (CMO)                          ...  Sun\n",
       "1     Registered Nurse                                       ...  Sun\n",
       "2     Dental Hygienist                                       ...  Sun\n",
       "3     Senior Salesforce Developer                            ...  Sun\n",
       "4     DEPUTY EXECUTIVE DIRECTOR, PROGRAM AND LEGAL ADVOCACY  ...  Sun\n",
       "...                                                     ...  ...  ...\n",
       "3319  Data Engineer/Architect with Security Clearance        ...  Sat\n",
       "3320  Data Engineer with Security Clearance                  ...  Sat\n",
       "3321  Data Engineer, Mid with Security Clearance             ...  Sat\n",
       "3322  Data Modeler, Senior with Security Clearance           ...  Sat\n",
       "3323  Data Engineer, Senior with Security Clearance          ...  Sat\n",
       "\n",
       "[3324 rows x 16 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df[\"Day\"] = all_df[\"Date_Posted\"].apply(lambda x : Convert_to_Day(x))\n",
    "all_df[\"Vday\"] = all_df[\"Valid_until\"].apply(lambda x : Convert_to_Day(x))\n",
    "all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQ37uThlwYVx"
   },
   "source": [
    "# Revisiting Working with Missing Data\n",
    "In Data Munging Part I, we removed missing data\n",
    "\n",
    "Sometimes you'll want to save that data for later so you can do some analysis on the erroneously provided or missing data\n",
    "This is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "894e3b68-39c8-4ae7-905c-fdd55849c24e",
    "executionInfo": {
     "elapsed": 22482,
     "status": "ok",
     "timestamp": 1605387495636,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "_ndu_wvtwYVx",
    "output_cleared": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This dataset replaced missing values with -1 \n",
    "# Store that data in different data frame\n",
    "index_missing = all_df[(all_df['Min_Salary'] == -1)].index\n",
    "\n",
    "#We will use this data as our test set.\n",
    "test_df = all_df.iloc[index_missing, :].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "550wgyEpwYVz"
   },
   "source": [
    "## Q11. Now that you have this missing data, you can now drop it from the dataframe. Write the code to do this below.\n",
    "**Hint: You should use the function `drop` that follows this format\n",
    "`df.drop(missing_data_index, axis=0, inplace=True)` where `df` is the dataframe\n",
    "and `missing_data_index` is a list of rows to drop from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 22472,
     "status": "ok",
     "timestamp": 1605387495636,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "2FN_2H76wYV0"
   },
   "outputs": [],
   "source": [
    "all_df.drop(index_missing, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTaePu3uwYV1"
   },
   "source": [
    "# Working with Duplicates\n",
    "Sometimes in your dataset because it is scraped from the web, there may be duplicates\n",
    "You'll need to check for these duplicates because it will impace your data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "05f30f12-33e9-476d-bcc0-67ebf2620207",
    "executionInfo": {
     "elapsed": 22466,
     "status": "ok",
     "timestamp": 1605387495637,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "PJqzuNI3wYV2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Check for duplicates in the data because our scraper was not perfect and could have scraped multiple entries\n",
    "cols = [col for col in all_df.columns if col not in ['Day' , 'Month']]\n",
    "\n",
    "#For training data \n",
    "train_series = all_df.duplicated(cols , keep = 'first')\n",
    "data_df      = all_df[~train_series].reset_index(drop = True)\n",
    "test_series  = test_df.duplicated(cols , keep = 'first')\n",
    "test_df      = test_df[~test_series].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OsJ6zO4OwYV3"
   },
   "source": [
    "# Looking for Unique Values in your Dataframe\n",
    "Sometiems you'll need to look for unique values in your dataframe \n",
    "Use the `unique` function to do this\n",
    "Follows this format `df['COL_NAME'].unique()` where df is the dataframe and COL_NAME is the column name in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "c82dc428-161a-48f0-9d1c-e9f957598ad7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22457,
     "status": "ok",
     "timestamp": 1605387495637,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "hmT2h0BLwYV4",
    "outputId": "681e80fa-15d3-4112-906e-28df5b66fbf3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NY' 'NJ' 'CA' 'KY' 'TX' 'TN' 'VA' 'MD' 'DC' 'NC']\n"
     ]
    }
   ],
   "source": [
    "# Find the Unique States\n",
    "print(all_df['State'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qD70kF2ywYV6"
   },
   "source": [
    "## Q12. Write the code to count the number of unique States from the previous operation. Name the variable num_states and print it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22447,
     "status": "ok",
     "timestamp": 1605387495638,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "U3cqXDmswYV7",
    "outputId": "e1a212a1-5e4b-4b9d-b80c-f9afbafb08e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(all_df['State'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "c7241844-5914-4c55-b335-12ed126b16ad",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22436,
     "status": "ok",
     "timestamp": 1605387495638,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "PHXGJd-TwYV8",
    "outputId": "01353c91-199f-4874-813c-b305f556a8d0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State of NY\n",
      "New York          240\n",
      "Williston Park    30 \n",
      "Staten Island     30 \n",
      "Mamaroneck        30 \n",
      "Maspeth           30 \n",
      "Name: City, dtype: int64\n",
      "\n",
      "State of NJ\n",
      "Jersey City    30\n",
      "Paramus        30\n",
      "Name: City, dtype: int64\n",
      "\n",
      "State of CA\n",
      "San Francisco          302\n",
      "South San Francisco    122\n",
      "Menlo Park             29 \n",
      "San Mateo              27 \n",
      "Redwood City           20 \n",
      "Name: City, dtype: int64\n",
      "\n",
      "State of KY\n",
      "Florence    1\n",
      "Name: City, dtype: int64\n",
      "\n",
      "State of TX\n",
      "Austin         132\n",
      "Dallas         79 \n",
      "Houston        67 \n",
      "San Antonio    41 \n",
      "Irving         40 \n",
      "Name: City, dtype: int64\n",
      "\n",
      "State of TN\n",
      "Chennai    1\n",
      "Name: City, dtype: int64\n",
      "\n",
      "State of VA\n",
      "Arlington      77\n",
      "McLean         50\n",
      "Reston         35\n",
      "Springfield    34\n",
      "Chantilly      29\n",
      "Name: City, dtype: int64\n",
      "\n",
      "State of MD\n",
      "Gaithersburg     41\n",
      "Rockville        36\n",
      "Silver Spring    25\n",
      "College Park     23\n",
      "Bethesda         20\n",
      "Name: City, dtype: int64\n",
      "\n",
      "State of DC\n",
      "Washington    155\n",
      "Name: City, dtype: int64\n",
      "\n",
      "State of NC\n",
      "Raleigh    1\n",
      "Name: City, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Let's explore the top 5 cites in which most job lisitngs are there\n",
    "for state in all_df['State'].unique():\n",
    "    print(f\"State of {state}\")\n",
    "    print(all_df[all_df['State'] == state]['City'].value_counts()[:5])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejDvz4JiwYV-"
   },
   "source": [
    "## Q13. What city has the most job openings? Write your answer below\n",
    "\n",
    "* San Fransico has the most job openings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALPuY3L3wYV_"
   },
   "source": [
    "## Q14. What city has the least job openings? What states do they occur in?\n",
    "\n",
    "Florence, Chennai, and Raleigh have the least job openings. They lie  in states KY, TN, and NC respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgZgkeuWwYV_"
   },
   "source": [
    "# Identifying and Removing Outliers\n",
    "In some cases you'll have outliers in your data. \n",
    "An `outlier` is an observation that lies an abnormal distance from other values in a random sample from a population. \n",
    "Sometimes negative numbers, zero, or really large numbers can be outliers in your sample population\n",
    "\n",
    "See your textbook Sampling from a Population https://www.inferentialthinking.com/chapters/10/2/Sampling_from_a_Population.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 22429,
     "status": "ok",
     "timestamp": 1605387495639,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "ZtEvdsKWwYV_"
   },
   "outputs": [],
   "source": [
    "# Dropping the states with only one\n",
    "# Saving this data for later\n",
    "index_outlier = all_df[(all_df['State'] =='NC') | (all_df['State'] =='TN') | (all_df['State'] =='KY')].index\n",
    "all_df.drop(index_outlier , inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "62149f95-3267-4876-b625-3f56011562d0",
    "id": "D2okJOJqwYWB",
    "tags": []
   },
   "source": [
    "# Visualizing the Data with pie charts\n",
    "The below code shows how to make a pie chart for the CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "10f7b273-f2e8-4efc-b77a-670bc1d61505",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "executionInfo": {
     "elapsed": 22637,
     "status": "ok",
     "timestamp": 1605387495856,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "MyMpSFrVwYWB",
    "outputId": "315a5680-040f-44a0-fc6f-15ffa310cc8b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans.\n",
      "findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans.\n"
     ]
    }
   ],
   "source": [
    "#Create a Pie Chart of CA and TX\n",
    "\n",
    "max_state = ['CA' ]\n",
    "for i,state in enumerate(max_state,1):\n",
    "    cities = all_df[all_df['State'] == state]['City'].value_counts()[:5].index.to_list()\n",
    "    counts = all_df[all_df[\"State\"] == state]['City'].value_counts()[:5].to_list()\n",
    "\n",
    "my_colors  = ['lightgray','lightblue','crimson', 'beige', 'yellow']\n",
    "my_explode = (0, 0.1, 0)\n",
    "\n",
    "plt.pie(counts,labels=cities,autopct='%1.1f%%',startangle=15, shadow = True, colors=my_colors)\n",
    "plt.title('California GlassDoor Cities')\n",
    "plt.axis('equal')\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZlNY0urwYWD"
   },
   "source": [
    "## Q15. Write the code to create a pie chart for TX. \n",
    "\n",
    "Add a title to your pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "4bc3c3b4-0926-4085-a064-5495faabaafc",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "executionInfo": {
     "elapsed": 22834,
     "status": "ok",
     "timestamp": 1605387496065,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "ySb-axWAwYWD",
    "outputId": "9008c423-0f72-4ed6-aef1-c5151eb07e48",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write code to create pie chart \n",
    "max_state = ['TX' ]\n",
    "for i,state in enumerate(max_state,1):\n",
    "    cities = all_df[all_df['State'] == state]['City'].value_counts()[:5].index.to_list()\n",
    "    counts = all_df[all_df[\"State\"] == state]['City'].value_counts()[:5].to_list()\n",
    "\n",
    "my_colors  = ['lightblue','lightsteelblue','silver', 'lightgrey', 'crimson']\n",
    "my_explode = (0, 0.1, 0)\n",
    "\n",
    "plt.pie(counts,labels=cities,autopct='%1.1f%%',startangle=15, shadow = True, colors=my_colors)\n",
    "plt.title('Texas GlassDoor Cities')\n",
    "plt.axis('equal')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99fvphChwYWG"
   },
   "source": [
    "# Using the Groupby functionality\n",
    "A groupby operation involves some combination of splitting the object, \n",
    "applying a function, and combining the results. \n",
    "\n",
    "This can be used to group large amounts of data and compute operations on these groups.\n",
    "\n",
    "This is shown in the example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "c039b142-8093-4ee0-920e-1ac38019eae8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22825,
     "status": "ok",
     "timestamp": 1605387496066,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "moYJ_4viwYWG",
    "outputId": "a26c5332-317e-4089-c517-ccbc94b099d1",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State\n",
       "CA    29611\n",
       "DC    21096\n",
       "MD    20268\n",
       "NJ    38471\n",
       "NY    20000\n",
       "TX    19857\n",
       "VA    29516\n",
       "Name: Min_Salary, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the minimal salary for the states \n",
    "states = all_df['State'].unique().tolist()\n",
    "\n",
    "min_sal =  all_df.groupby('State')['Min_Salary']\n",
    "max_sal =  all_df.groupby('State')['Max_Salary']\n",
    "\n",
    "min_sal.min()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFSm-zHRwYWI"
   },
   "source": [
    "## Q16. Use the groupby function to find the minimal salary for all companies\n",
    "Print this information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22815,
     "status": "ok",
     "timestamp": 1605387496067,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "Iz8gmuVIwYWI",
    "outputId": "3d119758-e2c8-48c4-a40f-c514c78ed08b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company\n",
       "159 Solutions, Inc.          110591\n",
       "1901 Group                   79171 \n",
       "22nd Century Technologies    85715 \n",
       "23andMe                      78913 \n",
       "911 Datamaster Inc           45694 \n",
       "                             ...   \n",
       "price.com                    122998\n",
       "steampunk                    108661\n",
       "sydata                       109626\n",
       "tekwissen                    24457 \n",
       "vidIQ                        137812\n",
       "Name: Min_Salary, Length: 959, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_sal_company =  all_df.groupby('Company')['Min_Salary']\n",
    "min_sal_company.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f438a547-c093-4935-a5ef-edd1d4fe86e5",
    "id": "Nbllq_SNwYWK",
    "tags": []
   },
   "source": [
    "## Extracting Features out of Job Description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "c762fb3d-281a-4141-823c-b11bac56f931",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 561,
     "status": "ok",
     "timestamp": 1605387870700,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "8mVK1wXowYWK",
    "outputId": "c1127ae0-5ae5-4c75-c2fd-d57ed7dbe155",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Principle Duties & Responsibilities:\n",
      "Analyze complex systems and troubleshoot and isolate system issues;\n",
      "Understand requirements for business users and translate into design specifications, utilizing thorough understanding of the Salesforce platform, Salesforce products and licensing models;\n",
      "Utilize thorough understanding of application development, project lifecycle, and methodologies and ability to work under tight deadlines and handle multiple detail-oriented tasks;\n",
      "Apply knowledge of Salesforce developmentand customizations, with APEX, Visual Force, API, Force.com and Workflows, taking into account com best practices, support mechanisms, procedures, and limitations, as well as NDR's unique needs;\n",
      "Responsible for Salesforce administration, release management and deployment as well as management of Salesforce.com sandboxes, including their integrations;\n",
      "Design and execute Salesforce.com configuration changes, leveraging the Salesforce interface to sync with internal tracking systems;\n",
      "Design, develop, and maintain integration and synchronization programs;\n",
      "Design the data model, user interface, business logic, and security for custom applications; and\n",
      "Design, develop, and customize software solutions for end users by using analysis and mathematical models to effectively predict and measure the results of the design using Chatter, Communities and other Salesforce applications.\n",
      "Requirements:\n",
      "Bachelor of Science degree or foreign equivalent in Information Systems, Computer Science, Computer Engineering, Software Engineering or a related field\n",
      "3 years of experience with the Salesforce platform, specifically: development with Apex, VisualForce, and Force.com;\n",
      "Design and execute Salesforce.com configuration changes, leveraging the Salesforce interface to sync with internal tracking systems;\n",
      "Salesforce administration, release management, and deployment\n",
      "Salesforce products and licensing models\n",
      "Management of Salesforce.com sandboxes, including their integrations; Chatter, Communities, and other Salesforce apps\n",
      "com best practices, support mechanisms, procedures, and limitations.\n",
      "What We Offer:\n",
      "We believe in a team-first culture, full of rewards and recognition for our employees. We are dedicated to our employees' success and growth within the company, through our employee mentorship and leadership programs.\n",
      "Our extensive benefits package includes:\n",
      "\n",
      "Medical, Dental, and Vision Benefits\n",
      "401(k) Match\n",
      "Paid Holidays, Volunteer Time Off, Sick Days, and Vacation\n",
      "10 Weeks Paid Parental Leave\n",
      "Pre-tax Transit Benefits\n",
      "Discounted Gym Membership\n",
      "No-cost Life Insurance Benefits\n",
      "About National Debt Relief:\n",
      "National Debt Relief is one of the country's largest and most reputable debt settlement companies. We are made up of energetic, smart, and compassionate individuals who are passionate about helping thousands of Americans with debt relief. Most importantly, we're all about helping our customers through a tough financial time in their lives with education and individual customer service.\n",
      "We are dedicated to helping individuals and families rid their lives of burdensome debt. We specialize in debt settlement and have negotiated settlements for thousands of creditor and collections accounts. We provide our clients with both our expertise and our proven results. This means helping consumers in their time of hardship to get out of debt with the least possible cost. It can also mean conducting financial consultations, educating the consumer, and recommending the appropriate solution. Our core services offer debt settlement as an alternative to bankruptcy, credit counseling, and debt consolidation. We become our clients' number one advocate to help them reestablish financial stability as quickly as possible.\n",
      "#ZR\n"
     ]
    }
   ],
   "source": [
    "# reset index first so that  we can use index 0 to access the first job description\n",
    "all_df = all_df.reset_index(drop=True)\n",
    "\n",
    "#Let's look at  how the job description actually looks\n",
    "x = all_df.Job_Desc[0].replace('\\n\\n' , '\\n')\n",
    "x = x.split('\\n')\n",
    "\n",
    "print(*x , sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d9074848-e4f7-42c6-aaf4-595b712909ea",
    "id": "J_U1YZL-wYWM",
    "tags": []
   },
   "source": [
    "## Q17. What are some observations that you noticed about the job description column. What's the format or structure of the job description\n",
    "\n",
    "The data in Job Description column is in string format with all the information regarding duties, requirements, and benefits. Since this is like a paragraph, this description has special string characters like new line characters. Sometimes, it has double new line characters probably to separate groups of texts into paragraphs.\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# Cleaning up HTML Artifiacts \n",
    "Sometimes you will need to clean up the data\n",
    "Use the regular expression library to do that\n",
    "Use the `replace` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "e465590a-695d-4905-bd2d-b96ad02278cf",
    "executionInfo": {
     "elapsed": 1415,
     "status": "ok",
     "timestamp": 1605388411949,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "d9J4GadUwYWM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Let's clean up the \\n and remove punction marks\n",
    "all_df['Job_Desc'] = all_df['Job_Desc'].replace('\\n\\n' , \" \" , regex = True)\n",
    "all_df['Job_Desc'] = all_df['Job_Desc'].replace('\\n' , \" \" , regex = True)\n",
    "\n",
    "test_df['Job_Desc'] = test_df['Job_Desc'].replace('\\n\\n' , \" \" , regex = True)\n",
    "test_df['Job_Desc'] = test_df['Job_Desc'].replace('\\n' , \" \" , regex = True)\n",
    "#Let's remove punctuation and Stopwords\n",
    "\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "def Remove_puncutations_stopwords(s):\n",
    "\n",
    "    s = ''.join([i for i in s if i not in string.punctuation])\n",
    "    s = remove_stopwords(s)\n",
    "    return s\n",
    "\n",
    "data_df['Job_Desc'] = data_df['Job_Desc'].apply(lambda x : Remove_puncutations_stopwords(x))\n",
    "\n",
    "data_df['Job_Desc'][2]\n",
    "test_df['Job_Desc'] = test_df['Job_Desc'].apply(lambda x : Remove_puncutations_stopwords(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6zAkpP-meuT"
   },
   "source": [
    "After you worked with some data sometimes you'll need to save it to work with late"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 16
    },
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1605388578620,
     "user": {
      "displayName": "Prabin Sapkota",
      "photoUrl": "https://lh6.googleusercontent.com/-doP6HgypWoA/AAAAAAAAAAI/AAAAAAAAADs/IVE1vPXCX6U/s64/photo.jpg",
      "userId": "10525827673897210712"
     },
     "user_tz": 300
    },
    "id": "f5dwTubSwYWQ",
    "outputId": "e33ea7c4-849b-4362-8246-d13519d6e974"
   },
   "outputs": [],
   "source": [
    "all_df.to_csv(\"all_data.csv\" , index = False)\n",
    "\n",
    "# to donwload file to local storage from google colabw\n",
    "# from google.colab import files\n",
    "# files.download(\"all_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "WCGGePSvwYVU",
    "bdQOUAX_wYVc",
    "ejDvz4JiwYV-",
    "ALPuY3L3wYV_"
   ],
   "name": "DataMungingPart2_Glassdoor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
